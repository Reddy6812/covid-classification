{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "16e8921a-fab2-4e0c-bd7f-1c971bd0de08",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using GPU: PhysicalDevice(name='/physical_device:GPU:0', device_type='GPU')\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-06-20 18:03:23.614323: I tensorflow/core/platform/cpu_feature_guard.cc:151] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations:  SSE4.1 SSE4.2 AVX AVX2 FMA\n",
      "To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
      "2024-06-20 18:03:24.328967: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1525] Created device /job:localhost/replica:0/task:0/device:GPU:0 with 78902 MB memory:  -> device: 0, name: NVIDIA A100-SXM4-80GB, pci bus id: 0000:b7:00.0, compute capability: 8.0\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/50\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-06-20 18:03:30.084749: I tensorflow/stream_executor/cuda/cuda_dnn.cc:366] Loaded cuDNN version 8201\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "205/205 [==============================] - ETA: 0s - loss: 420.9431 - accuracy: 0.8475"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/apps/tensorflow/2.7.0/lib/python3.9/site-packages/keras/engine/functional.py:1410: CustomMaskWarning: Custom mask layers require a config and must override get_config. When loading, the custom mask layer must be passed to the custom_objects argument.\n",
      "  layer_config = serialize_layer_fn(layer)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "205/205 [==============================] - 121s 552ms/step - loss: 420.9431 - accuracy: 0.8475 - val_loss: 79.2858 - val_accuracy: 0.7720 - lr: 1.0000e-04\n",
      "Epoch 2/50\n",
      "205/205 [==============================] - 112s 546ms/step - loss: 35.9850 - accuracy: 0.8804 - val_loss: 15.0321 - val_accuracy: 0.7716 - lr: 1.0000e-04\n",
      "Epoch 3/50\n",
      "205/205 [==============================] - 113s 552ms/step - loss: 7.9157 - accuracy: 0.8861 - val_loss: 5.0120 - val_accuracy: 0.8145 - lr: 1.0000e-04\n",
      "Epoch 4/50\n",
      "205/205 [==============================] - 112s 549ms/step - loss: 3.2017 - accuracy: 0.8889 - val_loss: 2.4932 - val_accuracy: 0.8550 - lr: 1.0000e-04\n",
      "Epoch 5/50\n",
      "205/205 [==============================] - 114s 556ms/step - loss: 2.0635 - accuracy: 0.8919 - val_loss: 1.9629 - val_accuracy: 0.8708 - lr: 1.0000e-04\n",
      "Epoch 6/50\n",
      "205/205 [==============================] - 110s 539ms/step - loss: 1.8478 - accuracy: 0.8942 - val_loss: 2.0330 - val_accuracy: 0.8303 - lr: 1.0000e-04\n",
      "Epoch 7/50\n",
      "205/205 [==============================] - 113s 554ms/step - loss: 1.8026 - accuracy: 0.8952 - val_loss: 1.8170 - val_accuracy: 0.8856 - lr: 1.0000e-04\n",
      "Epoch 8/50\n",
      "205/205 [==============================] - 111s 544ms/step - loss: 1.7823 - accuracy: 0.8955 - val_loss: 1.8478 - val_accuracy: 0.8730 - lr: 1.0000e-04\n",
      "Epoch 9/50\n",
      "205/205 [==============================] - 110s 541ms/step - loss: 1.7552 - accuracy: 0.8985 - val_loss: 1.9240 - val_accuracy: 0.8556 - lr: 1.0000e-04\n",
      "Epoch 10/50\n",
      "205/205 [==============================] - 112s 548ms/step - loss: 1.2792 - accuracy: 0.9033 - val_loss: 1.3366 - val_accuracy: 0.8913 - lr: 5.0000e-05\n",
      "Epoch 11/50\n",
      "205/205 [==============================] - 111s 543ms/step - loss: 1.2485 - accuracy: 0.9048 - val_loss: 1.3674 - val_accuracy: 0.8742 - lr: 5.0000e-05\n",
      "Epoch 12/50\n",
      "205/205 [==============================] - 110s 540ms/step - loss: 1.2341 - accuracy: 0.9064 - val_loss: 1.4330 - val_accuracy: 0.8642 - lr: 5.0000e-05\n",
      "Epoch 13/50\n",
      "205/205 [==============================] - 111s 545ms/step - loss: 0.9864 - accuracy: 0.9084 - val_loss: 1.0168 - val_accuracy: 0.9045 - lr: 2.5000e-05\n",
      "Epoch 14/50\n",
      "205/205 [==============================] - 112s 547ms/step - loss: 0.9696 - accuracy: 0.9085 - val_loss: 1.0486 - val_accuracy: 0.8856 - lr: 2.5000e-05\n",
      "Epoch 15/50\n",
      "205/205 [==============================] - 114s 558ms/step - loss: 0.9585 - accuracy: 0.9101 - val_loss: 0.9539 - val_accuracy: 0.9081 - lr: 2.5000e-05\n",
      "Epoch 16/50\n",
      "205/205 [==============================] - 112s 548ms/step - loss: 0.9514 - accuracy: 0.9106 - val_loss: 1.0309 - val_accuracy: 0.8951 - lr: 2.5000e-05\n",
      "Epoch 17/50\n",
      "205/205 [==============================] - 113s 553ms/step - loss: 0.9453 - accuracy: 0.9110 - val_loss: 1.0313 - val_accuracy: 0.8954 - lr: 2.5000e-05\n",
      "Epoch 18/50\n",
      "205/205 [==============================] - 112s 546ms/step - loss: 0.8093 - accuracy: 0.9138 - val_loss: 0.8796 - val_accuracy: 0.8975 - lr: 1.2500e-05\n",
      "Epoch 19/50\n",
      "205/205 [==============================] - 113s 554ms/step - loss: 0.7946 - accuracy: 0.9150 - val_loss: 0.8628 - val_accuracy: 0.8977 - lr: 1.2500e-05\n",
      "Epoch 20/50\n",
      "205/205 [==============================] - 112s 548ms/step - loss: 0.7938 - accuracy: 0.9148 - val_loss: 0.8158 - val_accuracy: 0.9103 - lr: 1.2500e-05\n",
      "Epoch 21/50\n",
      "205/205 [==============================] - 112s 549ms/step - loss: 0.7972 - accuracy: 0.9140 - val_loss: 0.8153 - val_accuracy: 0.9097 - lr: 1.2500e-05\n",
      "Epoch 22/50\n",
      "205/205 [==============================] - 111s 546ms/step - loss: 0.7929 - accuracy: 0.9147 - val_loss: 0.8178 - val_accuracy: 0.9085 - lr: 1.2500e-05\n",
      "Epoch 23/50\n",
      "205/205 [==============================] - 112s 546ms/step - loss: 0.7910 - accuracy: 0.9149 - val_loss: 0.8262 - val_accuracy: 0.9088 - lr: 1.2500e-05\n",
      "Epoch 24/50\n",
      "205/205 [==============================] - 111s 545ms/step - loss: 0.7257 - accuracy: 0.9161 - val_loss: 0.7389 - val_accuracy: 0.9135 - lr: 6.2500e-06\n",
      "Epoch 25/50\n",
      "205/205 [==============================] - 111s 544ms/step - loss: 0.7238 - accuracy: 0.9155 - val_loss: 0.7357 - val_accuracy: 0.9126 - lr: 6.2500e-06\n",
      "Epoch 26/50\n",
      "205/205 [==============================] - 111s 542ms/step - loss: 0.7251 - accuracy: 0.9156 - val_loss: 0.7901 - val_accuracy: 0.9029 - lr: 6.2500e-06\n",
      "Epoch 27/50\n",
      "205/205 [==============================] - 110s 541ms/step - loss: 0.7214 - accuracy: 0.9163 - val_loss: 0.8146 - val_accuracy: 0.8947 - lr: 6.2500e-06\n",
      "Epoch 28/50\n",
      "205/205 [==============================] - 112s 546ms/step - loss: 0.6860 - accuracy: 0.9172 - val_loss: 0.6918 - val_accuracy: 0.9152 - lr: 3.1250e-06\n",
      "Epoch 29/50\n",
      "205/205 [==============================] - 111s 546ms/step - loss: 0.6833 - accuracy: 0.9172 - val_loss: 0.6917 - val_accuracy: 0.9158 - lr: 3.1250e-06\n",
      "Epoch 30/50\n",
      "205/205 [==============================] - 111s 544ms/step - loss: 0.6843 - accuracy: 0.9168 - val_loss: 0.6935 - val_accuracy: 0.9147 - lr: 3.1250e-06\n",
      "Epoch 31/50\n",
      "205/205 [==============================] - 112s 550ms/step - loss: 0.6679 - accuracy: 0.9171 - val_loss: 0.6716 - val_accuracy: 0.9163 - lr: 1.5625e-06\n",
      "Epoch 32/50\n",
      "205/205 [==============================] - 112s 546ms/step - loss: 0.6660 - accuracy: 0.9172 - val_loss: 0.6760 - val_accuracy: 0.9149 - lr: 1.5625e-06\n",
      "Epoch 33/50\n",
      "205/205 [==============================] - 112s 547ms/step - loss: 0.6670 - accuracy: 0.9170 - val_loss: 0.6648 - val_accuracy: 0.9177 - lr: 1.5625e-06\n",
      "Epoch 34/50\n",
      "205/205 [==============================] - 111s 544ms/step - loss: 0.6635 - accuracy: 0.9176 - val_loss: 0.6716 - val_accuracy: 0.9164 - lr: 1.5625e-06\n",
      "Epoch 35/50\n",
      "205/205 [==============================] - 111s 544ms/step - loss: 0.6645 - accuracy: 0.9174 - val_loss: 0.6666 - val_accuracy: 0.9175 - lr: 1.5625e-06\n",
      "Epoch 36/50\n",
      "205/205 [==============================] - 113s 556ms/step - loss: 0.6584 - accuracy: 0.9172 - val_loss: 0.6641 - val_accuracy: 0.9160 - lr: 1.0000e-06\n",
      "Epoch 37/50\n",
      "205/205 [==============================] - 111s 544ms/step - loss: 0.6551 - accuracy: 0.9179 - val_loss: 0.6772 - val_accuracy: 0.9134 - lr: 1.0000e-06\n",
      "Epoch 38/50\n",
      "205/205 [==============================] - 111s 545ms/step - loss: 0.6570 - accuracy: 0.9175 - val_loss: 0.6586 - val_accuracy: 0.9171 - lr: 1.0000e-06\n",
      "Epoch 39/50\n",
      "205/205 [==============================] - 111s 545ms/step - loss: 0.6567 - accuracy: 0.9174 - val_loss: 0.6609 - val_accuracy: 0.9162 - lr: 1.0000e-06\n",
      "Epoch 40/50\n",
      "205/205 [==============================] - 114s 557ms/step - loss: 0.6560 - accuracy: 0.9176 - val_loss: 0.6584 - val_accuracy: 0.9170 - lr: 1.0000e-06\n",
      "Epoch 41/50\n",
      "205/205 [==============================] - 111s 544ms/step - loss: 0.6564 - accuracy: 0.9175 - val_loss: 0.6650 - val_accuracy: 0.9153 - lr: 1.0000e-06\n",
      "Epoch 42/50\n",
      "205/205 [==============================] - 112s 549ms/step - loss: 0.6556 - accuracy: 0.9178 - val_loss: 0.6554 - val_accuracy: 0.9180 - lr: 1.0000e-06\n",
      "Epoch 43/50\n",
      "205/205 [==============================] - 111s 543ms/step - loss: 0.6539 - accuracy: 0.9182 - val_loss: 0.6557 - val_accuracy: 0.9182 - lr: 1.0000e-06\n",
      "Epoch 44/50\n",
      "205/205 [==============================] - 114s 558ms/step - loss: 0.6601 - accuracy: 0.9170 - val_loss: 0.6547 - val_accuracy: 0.9179 - lr: 1.0000e-06\n",
      "Epoch 45/50\n",
      "205/205 [==============================] - 111s 544ms/step - loss: 0.6564 - accuracy: 0.9176 - val_loss: 0.6552 - val_accuracy: 0.9184 - lr: 1.0000e-06\n",
      "Epoch 46/50\n",
      "205/205 [==============================] - 111s 545ms/step - loss: 0.6564 - accuracy: 0.9178 - val_loss: 0.6613 - val_accuracy: 0.9166 - lr: 1.0000e-06\n",
      "Epoch 47/50\n",
      "205/205 [==============================] - 113s 552ms/step - loss: 0.6568 - accuracy: 0.9175 - val_loss: 0.6605 - val_accuracy: 0.9163 - lr: 1.0000e-06\n",
      "Epoch 48/50\n",
      "205/205 [==============================] - 112s 549ms/step - loss: 0.6542 - accuracy: 0.9182 - val_loss: 0.6582 - val_accuracy: 0.9175 - lr: 1.0000e-06\n",
      "Epoch 49/50\n",
      "205/205 [==============================] - 113s 551ms/step - loss: 0.6533 - accuracy: 0.9184 - val_loss: 0.6612 - val_accuracy: 0.9166 - lr: 1.0000e-06\n",
      "68/68 [==============================] - 28s 412ms/step - loss: 0.6697 - accuracy: 0.9153\n",
      "Test accuracy with segmentation model: 91.53%\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-06-20 19:35:24.546209: W tensorflow/python/util/util.cc:368] Sets are not currently considered sequences, but this may change in the future, so consider avoiding using them.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: final_modellatestt2/assets\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/apps/tensorflow/2.7.0/lib/python3.9/site-packages/keras/engine/functional.py:1410: CustomMaskWarning: Custom mask layers require a config and must override get_config. When loading, the custom mask layer must be passed to the custom_objects argument.\n",
      "  layer_config = serialize_layer_fn(layer)\n",
      "/apps/tensorflow/2.7.0/lib/python3.9/site-packages/keras/saving/saved_model/layer_serialization.py:112: CustomMaskWarning: Custom mask layers require a config and must override get_config. When loading, the custom mask layer must be passed to the custom_objects argument.\n",
      "  return generic_utils.serialize_keras_object(obj)\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import cv2\n",
    "import tensorflow as tf\n",
    "from tensorflow.keras.layers import Input, Conv2D, UpSampling2D, concatenate\n",
    "from tensorflow.keras.models import Model\n",
    "from tensorflow.keras.applications import ResNet50\n",
    "from tensorflow.keras.optimizers import Adam\n",
    "from tensorflow.keras.preprocessing.image import ImageDataGenerator\n",
    "from tensorflow.keras.callbacks import EarlyStopping, ReduceLROnPlateau, ModelCheckpoint\n",
    "from tensorflow.keras.regularizers import l1_l2\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "# TensorFlow GPU configuration\n",
    "physical_devices = tf.config.list_physical_devices('GPU')\n",
    "if len(physical_devices) > 0:\n",
    "    tf.config.experimental.set_memory_growth(physical_devices[0], True)\n",
    "    print(\"Using GPU:\", physical_devices[0])\n",
    "else:\n",
    "    print(\"No GPU found, using CPU\")\n",
    "\n",
    "# Set up paths and categories\n",
    "base_data_dir = '/blue/srampazzi/vi.gade/cov/covid'\n",
    "categories = ['COVID', 'Lung_Opacity', 'Normal', 'Viral_Pneumonia']\n",
    "\n",
    "# Load metadata and preprocess\n",
    "all_metadata = pd.DataFrame()\n",
    "for category in categories:\n",
    "    path = f'{base_data_dir}/{category}.metadata.xlsx'\n",
    "    df = pd.read_excel(path, usecols=['FILE NAME', 'FORMAT', 'SIZE'])\n",
    "    df['label'] = category\n",
    "    df['image_path'] = df['FILE NAME'].apply(lambda x: f'{base_data_dir}/{category}/images/{x}.png')\n",
    "    df['mask_path'] = df['FILE NAME'].apply(lambda x: f'{base_data_dir}/{category}/masks/{x}.png')\n",
    "    df = df[df['image_path'].apply(os.path.exists)]  # Ensure file exists\n",
    "    all_metadata = pd.concat([all_metadata, df], ignore_index=True)\n",
    "\n",
    "# Data splitting\n",
    "train_df, temp_df = train_test_split(all_metadata, test_size=0.4, random_state=42)\n",
    "val_df, test_df = train_test_split(temp_df, test_size=0.5, random_state=42)\n",
    "\n",
    "# Data augmentation\n",
    "datagen = ImageDataGenerator(\n",
    "    rotation_range=20,\n",
    "    width_shift_range=0.2,\n",
    "    height_shift_range=0.2,\n",
    "    shear_range=0.2,\n",
    "    zoom_range=0.2,\n",
    "    horizontal_flip=True,\n",
    "    fill_mode='nearest'\n",
    ")\n",
    "\n",
    "# Data generator function with data augmentation and masks\n",
    "def data_generator_segmentation(df, batch_size=32):\n",
    "    while True:\n",
    "        batch_paths = df.sample(n=batch_size)\n",
    "        batch_input = []\n",
    "        batch_output = []\n",
    "        for _, row in batch_paths.iterrows():\n",
    "            image = cv2.imread(row['image_path'], cv2.IMREAD_GRAYSCALE)  # Read as grayscale image\n",
    "            mask = cv2.imread(row['mask_path'], cv2.IMREAD_GRAYSCALE)\n",
    "            if mask is not None:\n",
    "                image = cv2.resize(image, (256, 256))\n",
    "                mask = cv2.resize(mask, (256, 256))\n",
    "                image = image / 255.0\n",
    "                mask = mask / 255.0\n",
    "                mask = np.round(mask).astype(np.float32)\n",
    "                image = np.stack((image,)*3, axis=-1)  # Replicate grayscale channel to 3 channels\n",
    "                image = datagen.random_transform(image)  # Apply random transform after replication\n",
    "                mask = np.expand_dims(mask, axis=-1)\n",
    "                batch_input.append(image)\n",
    "                batch_output.append(mask)\n",
    "        batch_x = np.array(batch_input)\n",
    "        batch_y = np.array(batch_output)\n",
    "        yield batch_x, batch_y\n",
    "\n",
    "# Setup data generators with data augmentation and masks\n",
    "train_gen_segmentation = data_generator_segmentation(train_df, batch_size=32)\n",
    "val_gen_segmentation = data_generator_segmentation(val_df, batch_size=32)\n",
    "test_gen_segmentation = data_generator_segmentation(test_df, batch_size=32)\n",
    "\n",
    "# Improved U-Net model with ResNet50 encoder and U-Net decoder maintaining 256x256 resolution\n",
    "def build_unet_resnet50(input_shape):\n",
    "    inputs = Input(shape=input_shape)\n",
    "\n",
    "    # Encoder: ResNet50\n",
    "    base_model = ResNet50(weights='imagenet', include_top=False, input_tensor=inputs)\n",
    "    skip_connection_names = ['conv1_relu', 'conv2_block3_out', 'conv3_block4_out', 'conv4_block6_out']\n",
    "    layers = [base_model.get_layer(name).output for name in skip_connection_names]\n",
    "\n",
    "    # Decoder\n",
    "    x = base_model.output\n",
    "    num_filters = 256\n",
    "    regularizer = l1_l2(l1=0.01, l2=0.1)\n",
    "    for i in range(len(layers)):\n",
    "        x = UpSampling2D()(x)\n",
    "        x = Conv2D(num_filters // (2 ** i), (3, 3), activation='relu', padding='same', kernel_regularizer=regularizer)(x)\n",
    "        x = concatenate([x, layers[-(i + 1)]])\n",
    "        x = Conv2D(num_filters // (2 ** i), (3, 3), activation='relu', padding='same', kernel_regularizer=regularizer)(x)\n",
    "\n",
    "    x = UpSampling2D(size=(2, 2))(x)\n",
    "    outputs = Conv2D(1, (1, 1), activation='sigmoid')(x)\n",
    "    model = Model(inputs, outputs)\n",
    "    return model\n",
    "\n",
    "input_shape = (256, 256, 3)  # Change input shape to 3 channels\n",
    "unet_resnet50 = build_unet_resnet50(input_shape)\n",
    "\n",
    "def dice_loss(y_true, y_pred):\n",
    "    y_true_f = tf.keras.backend.flatten(y_true)\n",
    "    y_pred_f = tf.keras.backend.flatten(y_pred)\n",
    "    intersection = tf.keras.backend.sum(y_true_f * y_pred_f)\n",
    "    return 1 - (2. * intersection + 1) / (tf.keras.backend.sum(y_true_f) + tf.keras.backend.sum(y_pred_f) + 1)\n",
    "\n",
    "def combined_loss(y_true, y_pred):\n",
    "    y_true = tf.cast(y_true, tf.float32)\n",
    "    y_pred = tf.cast(y_pred, tf.float32)\n",
    "    bce = tf.keras.losses.binary_crossentropy(y_true, y_pred)\n",
    "    dice = dice_loss(y_true, y_pred)\n",
    "    return bce + dice\n",
    "\n",
    "unet_resnet50.compile(optimizer=Adam(learning_rate=0.0001), loss=combined_loss, metrics=['accuracy'])\n",
    "\n",
    "early_stopping = EarlyStopping(monitor='val_loss', patience=5, restore_best_weights=True)\n",
    "reduce_lr = ReduceLROnPlateau(monitor='val_loss', factor=0.5, patience=2, min_lr=1e-6)\n",
    "model_checkpoint = ModelCheckpoint('best_modellatestt2.h5', save_best_only=True, monitor='val_loss')\n",
    "\n",
    "history_segmentation = unet_resnet50.fit(\n",
    "    train_gen_segmentation,\n",
    "    steps_per_epoch=len(train_df) // 32,\n",
    "    validation_data=val_gen_segmentation,\n",
    "    validation_steps=len(val_df) // 32,\n",
    "    epochs=50,\n",
    "    callbacks=[early_stopping, reduce_lr, model_checkpoint]\n",
    ")\n",
    "\n",
    "test_results_segmentation = unet_resnet50.evaluate(test_gen_segmentation, steps=len(test_df) // 32)\n",
    "print(f\"Test accuracy with segmentation model: {test_results_segmentation[1]*100:.2f}%\")\n",
    "\n",
    "unet_resnet50.save('final_modellatestt2')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "87b61eea-5a6b-4c43-b4f2-a33f05b08c81",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using GPU: PhysicalDevice(name='/physical_device:GPU:0', device_type='GPU')\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-06-20 19:42:35.900989: I tensorflow/core/platform/cpu_feature_guard.cc:151] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations:  SSE4.1 SSE4.2 AVX AVX2 FMA\n",
      "To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
      "2024-06-20 19:42:36.784121: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1525] Created device /job:localhost/replica:0/task:0/device:GPU:0 with 16659 MB memory:  -> device: 0, name: NVIDIA A100-SXM4-80GB, pci bus id: 0000:b7:00.0, compute capability: 8.0\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/50\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-06-20 19:42:42.999124: I tensorflow/stream_executor/cuda/cuda_dnn.cc:366] Loaded cuDNN version 8201\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "205/205 [==============================] - 122s 553ms/step - loss: 366.3969 - accuracy: 0.8439 - val_loss: 63.3599 - val_accuracy: 0.7688 - lr: 1.0000e-04\n",
      "Epoch 2/50\n",
      "205/205 [==============================] - 113s 552ms/step - loss: 27.9995 - accuracy: 0.8786 - val_loss: 12.0669 - val_accuracy: 0.7734 - lr: 1.0000e-04\n",
      "Epoch 3/50\n",
      "205/205 [==============================] - 115s 565ms/step - loss: 6.6921 - accuracy: 0.8855 - val_loss: 4.8252 - val_accuracy: 0.8050 - lr: 1.0000e-04\n",
      "Epoch 4/50\n",
      "205/205 [==============================] - 114s 557ms/step - loss: 3.3162 - accuracy: 0.8896 - val_loss: 3.1510 - val_accuracy: 0.8144 - lr: 1.0000e-04\n",
      "Epoch 5/50\n",
      "205/205 [==============================] - 113s 553ms/step - loss: 2.4273 - accuracy: 0.8914 - val_loss: 2.4743 - val_accuracy: 0.8405 - lr: 1.0000e-04\n",
      "Epoch 6/50\n",
      "205/205 [==============================] - 114s 558ms/step - loss: 2.1145 - accuracy: 0.8921 - val_loss: 2.1027 - val_accuracy: 0.8749 - lr: 1.0000e-04\n",
      "Epoch 7/50\n",
      "205/205 [==============================] - 114s 561ms/step - loss: 1.9444 - accuracy: 0.8953 - val_loss: 1.9633 - val_accuracy: 0.8725 - lr: 1.0000e-04\n",
      "Epoch 8/50\n",
      "205/205 [==============================] - 112s 550ms/step - loss: 1.8507 - accuracy: 0.8970 - val_loss: 2.0201 - val_accuracy: 0.8465 - lr: 1.0000e-04\n",
      "Epoch 9/50\n",
      "205/205 [==============================] - 112s 550ms/step - loss: 1.7848 - accuracy: 0.9006 - val_loss: 1.8356 - val_accuracy: 0.8817 - lr: 1.0000e-04\n",
      "Epoch 10/50\n",
      "205/205 [==============================] - 112s 550ms/step - loss: 1.7415 - accuracy: 0.9023 - val_loss: 2.0878 - val_accuracy: 0.8008 - lr: 1.0000e-04\n",
      "Epoch 11/50\n",
      "205/205 [==============================] - 112s 549ms/step - loss: 1.7200 - accuracy: 0.9028 - val_loss: 1.8016 - val_accuracy: 0.8752 - lr: 1.0000e-04\n",
      "Epoch 12/50\n",
      "205/205 [==============================] - 112s 549ms/step - loss: 1.6920 - accuracy: 0.9053 - val_loss: 1.8304 - val_accuracy: 0.8672 - lr: 1.0000e-04\n",
      "Epoch 13/50\n",
      "205/205 [==============================] - 113s 552ms/step - loss: 1.6728 - accuracy: 0.9061 - val_loss: 1.8064 - val_accuracy: 0.8797 - lr: 1.0000e-04\n",
      "Epoch 14/50\n",
      "205/205 [==============================] - 113s 552ms/step - loss: 1.1812 - accuracy: 0.9111 - val_loss: 1.2282 - val_accuracy: 0.9002 - lr: 5.0000e-05\n",
      "Epoch 15/50\n",
      "205/205 [==============================] - 113s 555ms/step - loss: 1.1516 - accuracy: 0.9119 - val_loss: 1.3392 - val_accuracy: 0.8667 - lr: 5.0000e-05\n",
      "Epoch 16/50\n",
      "205/205 [==============================] - 118s 580ms/step - loss: 1.1449 - accuracy: 0.9125 - val_loss: 1.3402 - val_accuracy: 0.8668 - lr: 5.0000e-05\n",
      "Epoch 17/50\n",
      "205/205 [==============================] - 113s 555ms/step - loss: 0.8863 - accuracy: 0.9155 - val_loss: 1.0047 - val_accuracy: 0.8935 - lr: 2.5000e-05\n",
      "Epoch 18/50\n",
      "205/205 [==============================] - 116s 569ms/step - loss: 0.8685 - accuracy: 0.9161 - val_loss: 0.9311 - val_accuracy: 0.8995 - lr: 2.5000e-05\n",
      "Epoch 19/50\n",
      "205/205 [==============================] - 118s 579ms/step - loss: 0.8665 - accuracy: 0.9164 - val_loss: 1.1858 - val_accuracy: 0.8453 - lr: 2.5000e-05\n",
      "Epoch 20/50\n",
      "205/205 [==============================] - 114s 558ms/step - loss: 0.8577 - accuracy: 0.9182 - val_loss: 0.9023 - val_accuracy: 0.9095 - lr: 2.5000e-05\n",
      "Epoch 21/50\n",
      "205/205 [==============================] - 114s 557ms/step - loss: 0.8566 - accuracy: 0.9181 - val_loss: 1.0893 - val_accuracy: 0.8709 - lr: 2.5000e-05\n",
      "Epoch 22/50\n",
      "205/205 [==============================] - 117s 573ms/step - loss: 0.8509 - accuracy: 0.9188 - val_loss: 0.8842 - val_accuracy: 0.9125 - lr: 2.5000e-05\n",
      "Epoch 23/50\n",
      "205/205 [==============================] - 118s 577ms/step - loss: 0.8512 - accuracy: 0.9185 - val_loss: 0.9235 - val_accuracy: 0.9060 - lr: 2.5000e-05\n",
      "Epoch 24/50\n",
      "205/205 [==============================] - 113s 555ms/step - loss: 0.8428 - accuracy: 0.9199 - val_loss: 0.9028 - val_accuracy: 0.9038 - lr: 2.5000e-05\n",
      "Epoch 25/50\n",
      "205/205 [==============================] - 114s 559ms/step - loss: 0.7148 - accuracy: 0.9208 - val_loss: 0.8386 - val_accuracy: 0.8945 - lr: 1.2500e-05\n",
      "Epoch 26/50\n",
      "205/205 [==============================] - 120s 590ms/step - loss: 0.7075 - accuracy: 0.9211 - val_loss: 0.7418 - val_accuracy: 0.9139 - lr: 1.2500e-05\n",
      "Epoch 27/50\n",
      "205/205 [==============================] - 118s 578ms/step - loss: 0.7090 - accuracy: 0.9206 - val_loss: 0.7272 - val_accuracy: 0.9169 - lr: 1.2500e-05\n",
      "Epoch 28/50\n",
      "205/205 [==============================] - 118s 580ms/step - loss: 0.7064 - accuracy: 0.9209 - val_loss: 0.8019 - val_accuracy: 0.8990 - lr: 1.2500e-05\n",
      "Epoch 29/50\n",
      "205/205 [==============================] - 114s 557ms/step - loss: 0.7060 - accuracy: 0.9208 - val_loss: 0.7327 - val_accuracy: 0.9160 - lr: 1.2500e-05\n",
      "Epoch 30/50\n",
      "205/205 [==============================] - 119s 583ms/step - loss: 0.6388 - accuracy: 0.9219 - val_loss: 0.6619 - val_accuracy: 0.9173 - lr: 6.2500e-06\n",
      "Epoch 31/50\n",
      "205/205 [==============================] - 120s 589ms/step - loss: 0.6358 - accuracy: 0.9215 - val_loss: 0.6464 - val_accuracy: 0.9184 - lr: 6.2500e-06\n",
      "Epoch 32/50\n",
      "205/205 [==============================] - 122s 596ms/step - loss: 0.6320 - accuracy: 0.9224 - val_loss: 0.7408 - val_accuracy: 0.8985 - lr: 6.2500e-06\n",
      "Epoch 33/50\n",
      "205/205 [==============================] - 120s 588ms/step - loss: 0.6291 - accuracy: 0.9231 - val_loss: 0.6585 - val_accuracy: 0.9171 - lr: 6.2500e-06\n",
      "Epoch 34/50\n",
      "205/205 [==============================] - 118s 576ms/step - loss: 0.5977 - accuracy: 0.9226 - val_loss: 0.6371 - val_accuracy: 0.9146 - lr: 3.1250e-06\n",
      "Epoch 35/50\n",
      "205/205 [==============================] - 119s 580ms/step - loss: 0.5980 - accuracy: 0.9220 - val_loss: 0.6133 - val_accuracy: 0.9179 - lr: 3.1250e-06\n",
      "Epoch 36/50\n",
      "205/205 [==============================] - 117s 572ms/step - loss: 0.5939 - accuracy: 0.9232 - val_loss: 0.6060 - val_accuracy: 0.9195 - lr: 3.1250e-06\n",
      "Epoch 37/50\n",
      "205/205 [==============================] - 113s 555ms/step - loss: 0.5920 - accuracy: 0.9236 - val_loss: 0.5984 - val_accuracy: 0.9223 - lr: 3.1250e-06\n",
      "Epoch 38/50\n",
      "205/205 [==============================] - 120s 588ms/step - loss: 0.5946 - accuracy: 0.9227 - val_loss: 0.6568 - val_accuracy: 0.9107 - lr: 3.1250e-06\n",
      "Epoch 39/50\n",
      "205/205 [==============================] - 117s 572ms/step - loss: 0.5900 - accuracy: 0.9237 - val_loss: 0.5938 - val_accuracy: 0.9229 - lr: 3.1250e-06\n",
      "Epoch 40/50\n",
      "205/205 [==============================] - 116s 570ms/step - loss: 0.5960 - accuracy: 0.9225 - val_loss: 0.6046 - val_accuracy: 0.9208 - lr: 3.1250e-06\n",
      "Epoch 41/50\n",
      "205/205 [==============================] - 113s 553ms/step - loss: 0.5945 - accuracy: 0.9228 - val_loss: 0.6008 - val_accuracy: 0.9216 - lr: 3.1250e-06\n",
      "Epoch 42/50\n",
      "205/205 [==============================] - 113s 553ms/step - loss: 0.5759 - accuracy: 0.9234 - val_loss: 0.5939 - val_accuracy: 0.9190 - lr: 1.5625e-06\n",
      "Epoch 43/50\n",
      "205/205 [==============================] - 113s 554ms/step - loss: 0.5746 - accuracy: 0.9236 - val_loss: 0.5786 - val_accuracy: 0.9230 - lr: 1.5625e-06\n",
      "Epoch 44/50\n",
      "205/205 [==============================] - 113s 553ms/step - loss: 0.5761 - accuracy: 0.9234 - val_loss: 0.5724 - val_accuracy: 0.9242 - lr: 1.5625e-06\n",
      "Epoch 45/50\n",
      "205/205 [==============================] - 114s 556ms/step - loss: 0.5720 - accuracy: 0.9242 - val_loss: 0.5786 - val_accuracy: 0.9228 - lr: 1.5625e-06\n",
      "Epoch 46/50\n",
      "205/205 [==============================] - 112s 548ms/step - loss: 0.5740 - accuracy: 0.9237 - val_loss: 0.5899 - val_accuracy: 0.9193 - lr: 1.5625e-06\n",
      "Epoch 47/50\n",
      "205/205 [==============================] - 112s 550ms/step - loss: 0.5651 - accuracy: 0.9241 - val_loss: 0.5729 - val_accuracy: 0.9226 - lr: 1.0000e-06\n",
      "Epoch 48/50\n",
      "205/205 [==============================] - 112s 549ms/step - loss: 0.5668 - accuracy: 0.9238 - val_loss: 0.5686 - val_accuracy: 0.9231 - lr: 1.0000e-06\n",
      "Epoch 49/50\n",
      "205/205 [==============================] - 113s 555ms/step - loss: 0.5639 - accuracy: 0.9244 - val_loss: 0.5844 - val_accuracy: 0.9204 - lr: 1.0000e-06\n",
      "Epoch 50/50\n",
      "205/205 [==============================] - 112s 550ms/step - loss: 0.5694 - accuracy: 0.9231 - val_loss: 0.5788 - val_accuracy: 0.9220 - lr: 1.0000e-06\n",
      "68/68 [==============================] - 28s 414ms/step - loss: 0.5806 - accuracy: 0.9211\n",
      "Test accuracy with segmentation model: 92.11%\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-06-20 21:19:11.948174: W tensorflow/python/util/util.cc:368] Sets are not currently considered sequences, but this may change in the future, so consider avoiding using them.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: unet_resnet50_segmentation_model/assets\n",
      "Model saved to unet_resnet50_segmentation_model directory\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/apps/tensorflow/2.7.0/lib/python3.9/site-packages/keras/engine/functional.py:1410: CustomMaskWarning: Custom mask layers require a config and must override get_config. When loading, the custom mask layer must be passed to the custom_objects argument.\n",
      "  layer_config = serialize_layer_fn(layer)\n",
      "/apps/tensorflow/2.7.0/lib/python3.9/site-packages/keras/saving/saved_model/layer_serialization.py:112: CustomMaskWarning: Custom mask layers require a config and must override get_config. When loading, the custom mask layer must be passed to the custom_objects argument.\n",
      "  return generic_utils.serialize_keras_object(obj)\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import cv2\n",
    "import tensorflow as tf\n",
    "from tensorflow.keras.layers import Input, Conv2D, UpSampling2D, concatenate\n",
    "from tensorflow.keras.models import Model\n",
    "from tensorflow.keras.applications import ResNet50\n",
    "from tensorflow.keras.optimizers import Adam\n",
    "from tensorflow.keras.preprocessing.image import ImageDataGenerator\n",
    "from tensorflow.keras.callbacks import EarlyStopping, ReduceLROnPlateau\n",
    "from tensorflow.keras.regularizers import l1_l2\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "# TensorFlow GPU configuration\n",
    "physical_devices = tf.config.list_physical_devices('GPU')\n",
    "if len(physical_devices) > 0:\n",
    "    tf.config.experimental.set_memory_growth(physical_devices[0], True)\n",
    "    print(\"Using GPU:\", physical_devices[0])\n",
    "else:\n",
    "    print(\"No GPU found, using CPU\")\n",
    "\n",
    "# Set up paths and categories\n",
    "base_data_dir = '/blue/srampazzi/vi.gade/cov/covid'\n",
    "categories = ['COVID', 'Lung_Opacity', 'Normal', 'Viral_Pneumonia']\n",
    "\n",
    "# Load metadata and preprocess\n",
    "all_metadata = pd.DataFrame()\n",
    "for category in categories:\n",
    "    path = f'{base_data_dir}/{category}.metadata.xlsx'\n",
    "    df = pd.read_excel(path, usecols=['FILE NAME', 'FORMAT', 'SIZE'])\n",
    "    df['label'] = category\n",
    "    df['image_path'] = df['FILE NAME'].apply(lambda x: f'{base_data_dir}/{category}/images/{x}.png')\n",
    "    df['mask_path'] = df['FILE NAME'].apply(lambda x: f'{base_data_dir}/{category}/masks/{x}.png')\n",
    "    df = df[df['image_path'].apply(os.path.exists)]  # Ensure file exists\n",
    "    all_metadata = pd.concat([all_metadata, df], ignore_index=True)\n",
    "\n",
    "# Data splitting\n",
    "train_df, temp_df = train_test_split(all_metadata, test_size=0.4, random_state=42)\n",
    "val_df, test_df = train_test_split(temp_df, test_size=0.5, random_state=42)\n",
    "\n",
    "# Data augmentation\n",
    "datagen = ImageDataGenerator(\n",
    "    rotation_range=20,\n",
    "    width_shift_range=0.2,\n",
    "    height_shift_range=0.2,\n",
    "    shear_range=0.2,\n",
    "    zoom_range=0.2,\n",
    "    horizontal_flip=True,\n",
    "    fill_mode='nearest'\n",
    ")\n",
    "\n",
    "# Data generator function with data augmentation and masks\n",
    "def data_generator_segmentation(df, batch_size=32):\n",
    "    while True:\n",
    "        batch_paths = df.sample(n=batch_size)\n",
    "        batch_input = []\n",
    "        batch_output = []\n",
    "        for _, row in batch_paths.iterrows():\n",
    "            image = cv2.imread(row['image_path'], cv2.IMREAD_COLOR)\n",
    "            mask = cv2.imread(row['mask_path'], cv2.IMREAD_GRAYSCALE)  # Load the mask\n",
    "            if mask is not None:  # Ensure mask is loaded correctly\n",
    "                image = cv2.resize(image, (256, 256))\n",
    "                mask = cv2.resize(mask, (256, 256))  # Keep mask size to 256x256\n",
    "                image = image / 255.0\n",
    "                mask = mask / 255.0\n",
    "                mask = np.round(mask).astype(np.float32)  # Ensure mask is binary and float32\n",
    "                image = datagen.random_transform(image)\n",
    "                mask = np.expand_dims(mask, axis=-1)  # Expand mask dimensions to (256, 256, 1)\n",
    "                batch_input.append(image)\n",
    "                batch_output.append(mask)  # Append mask directly\n",
    "        batch_x = np.array(batch_input)\n",
    "        batch_y = np.array(batch_output)\n",
    "        yield batch_x, batch_y\n",
    "\n",
    "# Setup data generators with data augmentation and masks\n",
    "train_gen_segmentation = data_generator_segmentation(train_df, batch_size=32)\n",
    "val_gen_segmentation = data_generator_segmentation(val_df, batch_size=32)\n",
    "test_gen_segmentation = data_generator_segmentation(test_df, batch_size=32)\n",
    "\n",
    "# Improved U-Net model with ResNet50 encoder and U-Net decoder maintaining 256x256 resolution\n",
    "def build_unet_resnet50(input_shape):\n",
    "    inputs = Input(shape=input_shape)\n",
    "\n",
    "    # Encoder: ResNet50\n",
    "    base_model = ResNet50(weights='imagenet', include_top=False, input_tensor=inputs)\n",
    "    skip_connection_names = ['conv1_relu', 'conv2_block3_out', 'conv3_block4_out', 'conv4_block6_out']\n",
    "    layers = [base_model.get_layer(name).output for name in skip_connection_names]\n",
    "\n",
    "    # Decoder\n",
    "    x = base_model.output\n",
    "    num_filters = 256\n",
    "    regularizer = l1_l2(l1=0.01, l2=0.01)\n",
    "    for i in range(len(layers)):\n",
    "        x = UpSampling2D()(x)\n",
    "        x = Conv2D(num_filters // (2 ** i), (3, 3), activation='relu', padding='same', kernel_regularizer=regularizer)(x)\n",
    "        x = concatenate([x, layers[-(i + 1)]])\n",
    "        x = Conv2D(num_filters // (2 ** i), (3, 3), activation='relu', padding='same', kernel_regularizer=regularizer)(x)\n",
    "\n",
    "    # Ensure final output matches the original input size\n",
    "    x = UpSampling2D(size=(2, 2))(x)  # Up-sample to 256x256\n",
    "    outputs = Conv2D(1, (1, 1), activation='sigmoid')(x)  # Use sigmoid activation for binary segmentation\n",
    "    model = Model(inputs, outputs)\n",
    "    return model\n",
    "\n",
    "input_shape = (256, 256, 3)\n",
    "unet_resnet50 = build_unet_resnet50(input_shape)\n",
    "\n",
    "# Define the combined loss function\n",
    "def dice_loss(y_true, y_pred):\n",
    "    y_true_f = tf.keras.backend.flatten(y_true)\n",
    "    y_pred_f = tf.keras.backend.flatten(y_pred)\n",
    "    intersection = tf.keras.backend.sum(y_true_f * y_pred_f)\n",
    "    return 1 - (2. * intersection + 1) / (tf.keras.backend.sum(y_true_f) + tf.keras.backend.sum(y_pred_f) + 1)\n",
    "\n",
    "def combined_loss(y_true, y_pred):\n",
    "    y_true = tf.cast(y_true, tf.float32)  # Ensure y_true is float32\n",
    "    y_pred = tf.cast(y_pred, tf.float32)  # Ensure y_pred is float32\n",
    "    bce = tf.keras.losses.binary_crossentropy(y_true, y_pred)\n",
    "    dice = dice_loss(y_true, y_pred)\n",
    "    return bce + dice\n",
    "\n",
    "unet_resnet50.compile(optimizer=Adam(learning_rate=0.0001), loss=combined_loss, metrics=['accuracy'])\n",
    "\n",
    "# Callbacks for early stopping and learning rate reduction\n",
    "early_stopping = EarlyStopping(monitor='val_loss', patience=5, restore_best_weights=True)\n",
    "reduce_lr = ReduceLROnPlateau(monitor='val_loss', factor=0.5, patience=2, min_lr=1e-6)\n",
    "\n",
    "# Model training with data augmentation and regularization\n",
    "history_segmentation = unet_resnet50.fit(\n",
    "    train_gen_segmentation,\n",
    "    steps_per_epoch=len(train_df) // 32,\n",
    "    validation_data=val_gen_segmentation,\n",
    "    validation_steps=len(val_df) // 32,\n",
    "    epochs=50,\n",
    "    callbacks=[early_stopping, reduce_lr]\n",
    ")\n",
    "\n",
    "# Evaluate the model on the test set with augmentation\n",
    "test_results_segmentation = unet_resnet50.evaluate(test_gen_segmentation, steps=len(test_df) // 32)\n",
    "print(f\"Test accuracy with segmentation model: {test_results_segmentation[1]*100:.2f}%\")\n",
    "\n",
    "# Save the trained model in TensorFlow SavedModel format\n",
    "model_tf_save_path = 'unet_resnet50_segmentation_model'\n",
    "unet_resnet50.save(model_tf_save_path, save_format='tf')\n",
    "print(f\"Model saved to {model_tf_save_path} directory\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "c72e80e2-cacf-4e90-853a-d3f844a86106",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using GPU: PhysicalDevice(name='/physical_device:GPU:0', device_type='GPU')\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-06-17 23:39:10.854138: I tensorflow/core/platform/cpu_feature_guard.cc:151] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations:  SSE4.1 SSE4.2 AVX AVX2 FMA\n",
      "To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
      "2024-06-17 23:39:11.617495: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1525] Created device /job:localhost/replica:0/task:0/device:GPU:0 with 78902 MB memory:  -> device: 0, name: NVIDIA A100-SXM4-80GB, pci bus id: 0000:07:00.0, compute capability: 8.0\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/20\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-06-17 23:39:17.432212: I tensorflow/stream_executor/cuda/cuda_dnn.cc:366] Loaded cuDNN version 8201\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "205/205 [==============================] - 121s 555ms/step - loss: 1.5226 - accuracy: 0.8641 - val_loss: 2.1848 - val_accuracy: 0.7752 - lr: 1.0000e-04\n",
      "Epoch 2/20\n",
      "205/205 [==============================] - 113s 552ms/step - loss: 1.0913 - accuracy: 0.8884 - val_loss: 1.4469 - val_accuracy: 0.7987 - lr: 1.0000e-04\n",
      "Epoch 3/20\n",
      "205/205 [==============================] - 112s 550ms/step - loss: 0.8948 - accuracy: 0.8973 - val_loss: 1.0858 - val_accuracy: 0.8629 - lr: 1.0000e-04\n",
      "Epoch 4/20\n",
      "205/205 [==============================] - 112s 549ms/step - loss: 0.7742 - accuracy: 0.9038 - val_loss: 0.8808 - val_accuracy: 0.8692 - lr: 1.0000e-04\n",
      "Epoch 5/20\n",
      "205/205 [==============================] - 112s 549ms/step - loss: 0.6938 - accuracy: 0.9095 - val_loss: 0.9028 - val_accuracy: 0.8560 - lr: 1.0000e-04\n",
      "Epoch 6/20\n",
      "205/205 [==============================] - 112s 550ms/step - loss: 0.6360 - accuracy: 0.9141 - val_loss: 0.6965 - val_accuracy: 0.8966 - lr: 1.0000e-04\n",
      "Epoch 7/20\n",
      "205/205 [==============================] - 114s 559ms/step - loss: 0.5911 - accuracy: 0.9178 - val_loss: 0.8201 - val_accuracy: 0.8713 - lr: 1.0000e-04\n",
      "Epoch 8/20\n",
      "205/205 [==============================] - 118s 576ms/step - loss: 0.5544 - accuracy: 0.9212 - val_loss: 0.6103 - val_accuracy: 0.9059 - lr: 1.0000e-04\n",
      "Epoch 9/20\n",
      "205/205 [==============================] - 117s 575ms/step - loss: 0.5249 - accuracy: 0.9241 - val_loss: 0.7320 - val_accuracy: 0.8870 - lr: 1.0000e-04\n",
      "Epoch 10/20\n",
      "205/205 [==============================] - 114s 557ms/step - loss: 0.5007 - accuracy: 0.9261 - val_loss: 0.6352 - val_accuracy: 0.8963 - lr: 1.0000e-04\n",
      "Epoch 11/20\n",
      "205/205 [==============================] - 114s 558ms/step - loss: 0.4612 - accuracy: 0.9324 - val_loss: 0.5165 - val_accuracy: 0.9216 - lr: 5.0000e-05\n",
      "Epoch 12/20\n",
      "205/205 [==============================] - 114s 559ms/step - loss: 0.4486 - accuracy: 0.9339 - val_loss: 0.6749 - val_accuracy: 0.8893 - lr: 5.0000e-05\n",
      "Epoch 13/20\n",
      "205/205 [==============================] - 114s 557ms/step - loss: 0.4386 - accuracy: 0.9349 - val_loss: 0.5113 - val_accuracy: 0.9196 - lr: 5.0000e-05\n",
      "Epoch 14/20\n",
      "205/205 [==============================] - 114s 557ms/step - loss: 0.4280 - accuracy: 0.9361 - val_loss: 0.9291 - val_accuracy: 0.8473 - lr: 5.0000e-05\n",
      "Epoch 15/20\n",
      "205/205 [==============================] - 114s 558ms/step - loss: 0.4170 - accuracy: 0.9373 - val_loss: 0.5256 - val_accuracy: 0.9141 - lr: 5.0000e-05\n",
      "Epoch 16/20\n",
      "205/205 [==============================] - 114s 556ms/step - loss: 0.4012 - accuracy: 0.9397 - val_loss: 0.6384 - val_accuracy: 0.8937 - lr: 2.5000e-05\n",
      "Epoch 17/20\n",
      "205/205 [==============================] - 113s 553ms/step - loss: 0.3903 - accuracy: 0.9416 - val_loss: 0.4433 - val_accuracy: 0.9331 - lr: 2.5000e-05\n",
      "Epoch 18/20\n",
      "205/205 [==============================] - 113s 555ms/step - loss: 0.3904 - accuracy: 0.9411 - val_loss: 0.4067 - val_accuracy: 0.9387 - lr: 2.5000e-05\n",
      "Epoch 19/20\n",
      "205/205 [==============================] - 113s 555ms/step - loss: 0.3839 - accuracy: 0.9420 - val_loss: 0.4229 - val_accuracy: 0.9335 - lr: 2.5000e-05\n",
      "Epoch 20/20\n",
      "205/205 [==============================] - 113s 554ms/step - loss: 0.3755 - accuracy: 0.9433 - val_loss: 0.5545 - val_accuracy: 0.9156 - lr: 2.5000e-05\n",
      "68/68 [==============================] - 28s 417ms/step - loss: 0.5561 - accuracy: 0.9152\n",
      "Test accuracy with segmentation model: 91.52%\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import cv2\n",
    "import tensorflow as tf\n",
    "from tensorflow.keras.layers import Input, Conv2D, UpSampling2D, concatenate\n",
    "from tensorflow.keras.models import Model\n",
    "from tensorflow.keras.applications import ResNet50\n",
    "from tensorflow.keras.optimizers import Adam\n",
    "from tensorflow.keras.preprocessing.image import ImageDataGenerator\n",
    "from tensorflow.keras.callbacks import EarlyStopping, ReduceLROnPlateau\n",
    "from tensorflow.keras.regularizers import l1_l2\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "# TensorFlow GPU configuration\n",
    "physical_devices = tf.config.list_physical_devices('GPU')\n",
    "if len(physical_devices) > 0:\n",
    "    tf.config.experimental.set_memory_growth(physical_devices[0], True)\n",
    "    print(\"Using GPU:\", physical_devices[0])\n",
    "else:\n",
    "    print(\"No GPU found, using CPU\")\n",
    "\n",
    "# Set up paths and categories\n",
    "base_data_dir = '/blue/srampazzi/vi.gade/cov/covid'\n",
    "categories = ['COVID', 'Lung_Opacity', 'Normal', 'Viral_Pneumonia']\n",
    "\n",
    "# Load metadata and preprocess\n",
    "all_metadata = pd.DataFrame()\n",
    "for category in categories:\n",
    "    path = f'{base_data_dir}/{category}.metadata.xlsx'\n",
    "    df = pd.read_excel(path, usecols=['FILE NAME', 'FORMAT', 'SIZE'])\n",
    "    df['label'] = category\n",
    "    df['image_path'] = df['FILE NAME'].apply(lambda x: f'{base_data_dir}/{category}/images/{x}.png')\n",
    "    df['mask_path'] = df['FILE NAME'].apply(lambda x: f'{base_data_dir}/{category}/masks/{x}.png')\n",
    "    df = df[df['image_path'].apply(os.path.exists)]  # Ensure file exists\n",
    "    all_metadata = pd.concat([all_metadata, df], ignore_index=True)\n",
    "\n",
    "# Data splitting\n",
    "train_df, temp_df = train_test_split(all_metadata, test_size=0.4, random_state=42)\n",
    "val_df, test_df = train_test_split(temp_df, test_size=0.5, random_state=42)\n",
    "\n",
    "# Data augmentation\n",
    "datagen = ImageDataGenerator(\n",
    "    rotation_range=20,\n",
    "    width_shift_range=0.2,\n",
    "    height_shift_range=0.2,\n",
    "    shear_range=0.2,\n",
    "    zoom_range=0.2,\n",
    "    horizontal_flip=True,\n",
    "    fill_mode='nearest'\n",
    ")\n",
    "\n",
    "# Data generator function with data augmentation and masks\n",
    "def data_generator_segmentation(df, batch_size=32):\n",
    "    while True:\n",
    "        batch_paths = df.sample(n=batch_size)\n",
    "        batch_input = []\n",
    "        batch_output = []\n",
    "        for _, row in batch_paths.iterrows():\n",
    "            image = cv2.imread(row['image_path'], cv2.IMREAD_COLOR)\n",
    "            mask = cv2.imread(row['mask_path'], cv2.IMREAD_GRAYSCALE)  # Load the mask\n",
    "            if mask is not None:  # Ensure mask is loaded correctly\n",
    "                image = cv2.resize(image, (256, 256))\n",
    "                mask = cv2.resize(mask, (256, 256))  # Keep mask size to 256x256\n",
    "                image = image / 255.0\n",
    "                mask = mask / 255.0\n",
    "                mask = np.round(mask).astype(np.float32)  # Ensure mask is binary and float32\n",
    "                image = datagen.random_transform(image)\n",
    "                mask = np.expand_dims(mask, axis=-1)  # Expand mask dimensions to (256, 256, 1)\n",
    "                batch_input.append(image)\n",
    "                batch_output.append(mask)  # Append mask directly\n",
    "        batch_x = np.array(batch_input)\n",
    "        batch_y = np.array(batch_output)\n",
    "        yield batch_x, batch_y\n",
    "\n",
    "# Setup data generators with data augmentation and masks\n",
    "train_gen_segmentation = data_generator_segmentation(train_df, batch_size=32)\n",
    "val_gen_segmentation = data_generator_segmentation(val_df, batch_size=32)\n",
    "test_gen_segmentation = data_generator_segmentation(test_df, batch_size=32)\n",
    "\n",
    "# Improved U-Net model with ResNet50 encoder and U-Net decoder maintaining 256x256 resolution\n",
    "def build_unet_resnet50(input_shape):\n",
    "    inputs = Input(shape=input_shape)\n",
    "\n",
    "    # Encoder: ResNet50\n",
    "    base_model = ResNet50(weights='imagenet', include_top=False, input_tensor=inputs)\n",
    "    skip_connection_names = ['conv1_relu', 'conv2_block3_out', 'conv3_block4_out', 'conv4_block6_out']\n",
    "    layers = [base_model.get_layer(name).output for name in skip_connection_names]\n",
    "\n",
    "    # Decoder\n",
    "    x = base_model.output\n",
    "    num_filters = 256\n",
    "    regularizer = l1_l2(l1=1e-5, l2=1e-4)\n",
    "    for i in range(len(layers)):\n",
    "        x = UpSampling2D()(x)\n",
    "        x = Conv2D(num_filters // (2 ** i), (3, 3), activation='relu', padding='same', kernel_regularizer=regularizer)(x)\n",
    "        x = concatenate([x, layers[-(i + 1)]])\n",
    "        x = Conv2D(num_filters // (2 ** i), (3, 3), activation='relu', padding='same', kernel_regularizer=regularizer)(x)\n",
    "\n",
    "    # Ensure final output matches the original input size\n",
    "    x = UpSampling2D(size=(2, 2))(x)  # Up-sample to 256x256\n",
    "    outputs = Conv2D(1, (1, 1), activation='sigmoid')(x)  # Use sigmoid activation for binary segmentation\n",
    "    model = Model(inputs, outputs)\n",
    "    return model\n",
    "\n",
    "input_shape = (256, 256, 3)\n",
    "unet_resnet50 = build_unet_resnet50(input_shape)\n",
    "\n",
    "# Define the combined loss function\n",
    "def dice_loss(y_true, y_pred):\n",
    "    y_true_f = tf.keras.backend.flatten(y_true)\n",
    "    y_pred_f = tf.keras.backend.flatten(y_pred)\n",
    "    intersection = tf.keras.backend.sum(y_true_f * y_pred_f)\n",
    "    return 1 - (2. * intersection + 1) / (tf.keras.backend.sum(y_true_f) + tf.keras.backend.sum(y_pred_f) + 1)\n",
    "\n",
    "def combined_loss(y_true, y_pred):\n",
    "    y_true = tf.cast(y_true, tf.float32)  # Ensure y_true is float32\n",
    "    y_pred = tf.cast(y_pred, tf.float32)  # Ensure y_pred is float32\n",
    "    bce = tf.keras.losses.binary_crossentropy(y_true, y_pred)\n",
    "    dice = dice_loss(y_true, y_pred)\n",
    "    return bce + dice\n",
    "\n",
    "unet_resnet50.compile(optimizer=Adam(learning_rate=0.0001), loss=combined_loss, metrics=['accuracy'])\n",
    "\n",
    "# Callbacks for early stopping and learning rate reduction\n",
    "early_stopping = EarlyStopping(monitor='val_loss', patience=5, restore_best_weights=True)\n",
    "reduce_lr = ReduceLROnPlateau(monitor='val_loss', factor=0.5, patience=2, min_lr=1e-6)\n",
    "\n",
    "# Model training with data augmentation and regularization\n",
    "history_segmentation = unet_resnet50.fit(\n",
    "    train_gen_segmentation,\n",
    "    steps_per_epoch=len(train_df) // 32,\n",
    "    validation_data=val_gen_segmentation,\n",
    "    validation_steps=len(val_df) // 32,\n",
    "    epochs=20,\n",
    "    callbacks=[early_stopping, reduce_lr]\n",
    ")\n",
    "\n",
    "# Evaluate the model on the test set with augmentation\n",
    "test_results_segmentation = unet_resnet50.evaluate(test_gen_segmentation, steps=len(test_df) // 32)\n",
    "print(f\"Test accuracy with segmentation model: {test_results_segmentation[1]*100:.2f}%\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "962d48bc-a4c9-4a9a-bb20-36418b723325",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using GPU: PhysicalDevice(name='/physical_device:GPU:0', device_type='GPU')\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-06-17 18:41:40.292346: I tensorflow/core/platform/cpu_feature_guard.cc:151] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations:  SSE4.1 SSE4.2 AVX AVX2 FMA\n",
      "To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
      "2024-06-17 18:41:41.106807: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1525] Created device /job:localhost/replica:0/task:0/device:GPU:0 with 78911 MB memory:  -> device: 0, name: NVIDIA A100-SXM4-80GB, pci bus id: 0000:87:00.0, compute capability: 8.0\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/20\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-06-17 18:41:46.553818: I tensorflow/stream_executor/cuda/cuda_dnn.cc:366] Loaded cuDNN version 8201\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "205/205 [==============================] - 127s 586ms/step - loss: 0.6818 - accuracy: 0.8632 - val_loss: 1.3180 - val_accuracy: 0.7742 - lr: 1.0000e-04\n",
      "Epoch 2/20\n",
      "205/205 [==============================] - 126s 616ms/step - loss: 0.5534 - accuracy: 0.8891 - val_loss: 0.8935 - val_accuracy: 0.8324 - lr: 1.0000e-04\n",
      "Epoch 3/20\n",
      "205/205 [==============================] - 126s 616ms/step - loss: 0.5084 - accuracy: 0.8990 - val_loss: 0.8455 - val_accuracy: 0.8329 - lr: 1.0000e-04\n",
      "Epoch 4/20\n",
      "205/205 [==============================] - 126s 616ms/step - loss: 0.4796 - accuracy: 0.9052 - val_loss: 0.7185 - val_accuracy: 0.8411 - lr: 1.0000e-04\n",
      "Epoch 5/20\n",
      "205/205 [==============================] - 124s 607ms/step - loss: 0.4429 - accuracy: 0.9125 - val_loss: 0.6573 - val_accuracy: 0.8631 - lr: 1.0000e-04\n",
      "Epoch 6/20\n",
      "205/205 [==============================] - 134s 654ms/step - loss: 0.4269 - accuracy: 0.9158 - val_loss: 0.5868 - val_accuracy: 0.8769 - lr: 1.0000e-04\n",
      "Epoch 7/20\n",
      "205/205 [==============================] - 129s 633ms/step - loss: 0.4051 - accuracy: 0.9206 - val_loss: 0.7960 - val_accuracy: 0.8473 - lr: 1.0000e-04\n",
      "Epoch 8/20\n",
      "205/205 [==============================] - 123s 602ms/step - loss: 0.3940 - accuracy: 0.9226 - val_loss: 0.6078 - val_accuracy: 0.8799 - lr: 1.0000e-04\n",
      "Epoch 9/20\n",
      "205/205 [==============================] - 124s 606ms/step - loss: 0.3553 - accuracy: 0.9305 - val_loss: 0.4534 - val_accuracy: 0.9102 - lr: 5.0000e-05\n",
      "Epoch 10/20\n",
      "205/205 [==============================] - 125s 614ms/step - loss: 0.3460 - accuracy: 0.9324 - val_loss: 0.4072 - val_accuracy: 0.9221 - lr: 5.0000e-05\n",
      "Epoch 11/20\n",
      "205/205 [==============================] - 118s 578ms/step - loss: 0.3371 - accuracy: 0.9342 - val_loss: 0.5678 - val_accuracy: 0.8911 - lr: 5.0000e-05\n",
      "Epoch 12/20\n",
      "205/205 [==============================] - 123s 602ms/step - loss: 0.3320 - accuracy: 0.9351 - val_loss: 0.4979 - val_accuracy: 0.9023 - lr: 5.0000e-05\n",
      "Epoch 13/20\n",
      "205/205 [==============================] - 123s 603ms/step - loss: 0.3152 - accuracy: 0.9383 - val_loss: 0.6360 - val_accuracy: 0.8771 - lr: 2.5000e-05\n",
      "Epoch 14/20\n",
      "205/205 [==============================] - 123s 603ms/step - loss: 0.3102 - accuracy: 0.9395 - val_loss: 0.5007 - val_accuracy: 0.9063 - lr: 2.5000e-05\n",
      "Epoch 15/20\n",
      "205/205 [==============================] - 124s 605ms/step - loss: 0.2986 - accuracy: 0.9416 - val_loss: 0.3860 - val_accuracy: 0.9250 - lr: 1.2500e-05\n",
      "Epoch 16/20\n",
      "205/205 [==============================] - 122s 598ms/step - loss: 0.2986 - accuracy: 0.9419 - val_loss: 0.4002 - val_accuracy: 0.9241 - lr: 1.2500e-05\n",
      "Epoch 17/20\n",
      "205/205 [==============================] - 124s 606ms/step - loss: 0.2952 - accuracy: 0.9425 - val_loss: 0.3258 - val_accuracy: 0.9367 - lr: 1.2500e-05\n",
      "Epoch 18/20\n",
      "205/205 [==============================] - 119s 581ms/step - loss: 0.2926 - accuracy: 0.9428 - val_loss: 0.3295 - val_accuracy: 0.9358 - lr: 1.2500e-05\n",
      "Epoch 19/20\n",
      "205/205 [==============================] - 120s 588ms/step - loss: 0.2898 - accuracy: 0.9436 - val_loss: 0.3847 - val_accuracy: 0.9263 - lr: 1.2500e-05\n",
      "Epoch 20/20\n",
      "205/205 [==============================] - 126s 617ms/step - loss: 0.2870 - accuracy: 0.9441 - val_loss: 0.5189 - val_accuracy: 0.9026 - lr: 6.2500e-06\n",
      "68/68 [==============================] - 30s 446ms/step - loss: 0.5164 - accuracy: 0.9032\n",
      "Test accuracy with segmentation model: 90.32%\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import cv2\n",
    "import tensorflow as tf\n",
    "from tensorflow.keras.layers import Input, Conv2D, UpSampling2D, concatenate\n",
    "from tensorflow.keras.models import Model\n",
    "from tensorflow.keras.applications import ResNet50\n",
    "from tensorflow.keras.optimizers import Adam\n",
    "from tensorflow.keras.preprocessing.image import ImageDataGenerator\n",
    "from tensorflow.keras.callbacks import EarlyStopping, ReduceLROnPlateau\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "# TensorFlow GPU configuration\n",
    "physical_devices = tf.config.list_physical_devices('GPU')\n",
    "if len(physical_devices) > 0:\n",
    "    tf.config.experimental.set_memory_growth(physical_devices[0], True)\n",
    "    print(\"Using GPU:\", physical_devices[0])\n",
    "else:\n",
    "    print(\"No GPU found, using CPU\")\n",
    "\n",
    "# Set up paths and categories\n",
    "base_data_dir = '/blue/srampazzi/vi.gade/cov/covid'\n",
    "categories = ['COVID', 'Lung_Opacity', 'Normal', 'Viral_Pneumonia']\n",
    "\n",
    "# Load metadata and preprocess\n",
    "all_metadata = pd.DataFrame()\n",
    "for category in categories:\n",
    "    path = f'{base_data_dir}/{category}.metadata.xlsx'\n",
    "    df = pd.read_excel(path, usecols=['FILE NAME', 'FORMAT', 'SIZE'])\n",
    "    df['label'] = category\n",
    "    df['image_path'] = df['FILE NAME'].apply(lambda x: f'{base_data_dir}/{category}/images/{x}.png')\n",
    "    df['mask_path'] = df['FILE NAME'].apply(lambda x: f'{base_data_dir}/{category}/masks/{x}.png')\n",
    "    df = df[df['image_path'].apply(os.path.exists)]  # Ensure file exists\n",
    "    all_metadata = pd.concat([all_metadata, df], ignore_index=True)\n",
    "\n",
    "# Data splitting\n",
    "train_df, temp_df = train_test_split(all_metadata, test_size=0.4, random_state=42)\n",
    "val_df, test_df = train_test_split(temp_df, test_size=0.5, random_state=42)\n",
    "\n",
    "# Data augmentation\n",
    "datagen = ImageDataGenerator(\n",
    "    rotation_range=20,\n",
    "    width_shift_range=0.2,\n",
    "    height_shift_range=0.2,\n",
    "    shear_range=0.2,\n",
    "    zoom_range=0.2,\n",
    "    horizontal_flip=True,\n",
    "    fill_mode='nearest'\n",
    ")\n",
    "\n",
    "# Data generator function with data augmentation and masks\n",
    "def data_generator_segmentation(df, batch_size=32):\n",
    "    while True:\n",
    "        batch_paths = df.sample(n=batch_size)\n",
    "        batch_input = []\n",
    "        batch_output = []\n",
    "        for _, row in batch_paths.iterrows():\n",
    "            image = cv2.imread(row['image_path'], cv2.IMREAD_COLOR)\n",
    "            mask = cv2.imread(row['mask_path'], cv2.IMREAD_GRAYSCALE)  # Load the mask\n",
    "            if mask is not None:  # Ensure mask is loaded correctly\n",
    "                image = cv2.resize(image, (256, 256))\n",
    "                mask = cv2.resize(mask, (256, 256))  # Keep mask size to 256x256\n",
    "                image = image / 255.0\n",
    "                mask = mask / 255.0\n",
    "                mask = np.round(mask).astype(np.float32)  # Ensure mask is binary and float32\n",
    "                image = datagen.random_transform(image)\n",
    "                mask = np.expand_dims(mask, axis=-1)  # Expand mask dimensions to (256, 256, 1)\n",
    "                batch_input.append(image)\n",
    "                batch_output.append(mask)  # Append mask directly\n",
    "        batch_x = np.array(batch_input)\n",
    "        batch_y = np.array(batch_output)\n",
    "        yield batch_x, batch_y\n",
    "\n",
    "# Setup data generators with data augmentation and masks\n",
    "train_gen_segmentation = data_generator_segmentation(train_df, batch_size=32)\n",
    "val_gen_segmentation = data_generator_segmentation(val_df, batch_size=32)\n",
    "test_gen_segmentation = data_generator_segmentation(test_df, batch_size=32)\n",
    "\n",
    "# Improved U-Net model with ResNet50 encoder and U-Net decoder maintaining 256x256 resolution\n",
    "def build_unet_resnet50(input_shape):\n",
    "    inputs = Input(shape=input_shape)\n",
    "\n",
    "    # Encoder: ResNet50\n",
    "    base_model = ResNet50(weights='imagenet', include_top=False, input_tensor=inputs)\n",
    "    skip_connection_names = ['conv1_relu', 'conv2_block3_out', 'conv3_block4_out', 'conv4_block6_out']\n",
    "    layers = [base_model.get_layer(name).output for name in skip_connection_names]\n",
    "\n",
    "    # Decoder\n",
    "    x = base_model.output\n",
    "    num_filters = 256\n",
    "    for i in range(len(layers)):\n",
    "        x = UpSampling2D()(x)\n",
    "        x = Conv2D(num_filters // (2 ** i), (3, 3), activation='relu', padding='same')(x)\n",
    "        x = concatenate([x, layers[-(i + 1)]])\n",
    "        x = Conv2D(num_filters // (2 ** i), (3, 3), activation='relu', padding='same')(x)\n",
    "\n",
    "    # Ensure final output matches the original input size\n",
    "    x = UpSampling2D(size=(2, 2))(x)  # Up-sample to 256x256\n",
    "    outputs = Conv2D(1, (1, 1), activation='sigmoid')(x)  # Use sigmoid activation for binary segmentation\n",
    "    model = Model(inputs, outputs)\n",
    "    return model\n",
    "\n",
    "input_shape = (256, 256, 3)\n",
    "unet_resnet50 = build_unet_resnet50(input_shape)\n",
    "\n",
    "# Define the combined loss function\n",
    "def dice_loss(y_true, y_pred):\n",
    "    y_true_f = tf.keras.backend.flatten(y_true)\n",
    "    y_pred_f = tf.keras.backend.flatten(y_pred)\n",
    "    intersection = tf.keras.backend.sum(y_true_f * y_pred_f)\n",
    "    return 1 - (2. * intersection + 1) / (tf.keras.backend.sum(y_true_f) + tf.keras.backend.sum(y_pred_f) + 1)\n",
    "\n",
    "def combined_loss(y_true, y_pred):\n",
    "    y_true = tf.cast(y_true, tf.float32)  # Ensure y_true is float32\n",
    "    y_pred = tf.cast(y_pred, tf.float32)  # Ensure y_pred is float32\n",
    "    bce = tf.keras.losses.binary_crossentropy(y_true, y_pred)\n",
    "    dice = dice_loss(y_true, y_pred)\n",
    "    return bce + dice\n",
    "\n",
    "unet_resnet50.compile(optimizer=Adam(learning_rate=0.0001), loss=combined_loss, metrics=['accuracy'])\n",
    "\n",
    "# Callbacks for early stopping and learning rate reduction\n",
    "early_stopping = EarlyStopping(monitor='val_loss', patience=5, restore_best_weights=True)\n",
    "reduce_lr = ReduceLROnPlateau(monitor='val_loss', factor=0.5, patience=2, min_lr=1e-6)\n",
    "\n",
    "# Model training with data augmentation and regularization\n",
    "history_segmentation = unet_resnet50.fit(\n",
    "    train_gen_segmentation,\n",
    "    steps_per_epoch=len(train_df) // 32,\n",
    "    validation_data=val_gen_segmentation,\n",
    "    validation_steps=len(val_df) // 32,\n",
    "    epochs=20,\n",
    "    callbacks=[early_stopping, reduce_lr]\n",
    ")\n",
    "\n",
    "# Evaluate the model on the test set with augmentation\n",
    "test_results_segmentation = unet_resnet50.evaluate(test_gen_segmentation, steps=len(test_df) // 32)\n",
    "print(f\"Test accuracy with segmentation model: {test_results_segmentation[1]*100:.2f}%\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cba538bc-2968-4f36-89fe-541e7df1678a",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "d435fb64-ee59-4a86-8a6a-9148207b86c3",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using GPU: PhysicalDevice(name='/physical_device:GPU:0', device_type='GPU')\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-06-17 18:14:24.581476: I tensorflow/core/platform/cpu_feature_guard.cc:151] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations:  SSE4.1 SSE4.2 AVX AVX2 FMA\n",
      "To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
      "2024-06-17 18:14:25.375583: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1525] Created device /job:localhost/replica:0/task:0/device:GPU:0 with 78911 MB memory:  -> device: 0, name: NVIDIA A100-SXM4-80GB, pci bus id: 0000:87:00.0, compute capability: 8.0\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/20\n",
      "combined_loss: y_true shape: (None, None, None, None), y_pred shape: (None, 128, 128, 1)\n",
      "combined_loss: y_true shape: (None, None, None, None), y_pred shape: (None, 128, 128, 1)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-06-17 18:14:30.892095: I tensorflow/stream_executor/cuda/cuda_dnn.cc:366] Loaded cuDNN version 8201\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "205/205 [==============================] - ETA: 0s - loss: 0.6645 - accuracy: 0.8612combined_loss: y_true shape: (None, None, None, None), y_pred shape: (None, 128, 128, 1)\n",
      "205/205 [==============================] - 136s 629ms/step - loss: 0.6645 - accuracy: 0.8612 - val_loss: 1.0314 - val_accuracy: 0.8137 - lr: 1.0000e-04\n",
      "Epoch 2/20\n",
      "205/205 [==============================] - 124s 610ms/step - loss: 0.5515 - accuracy: 0.8882 - val_loss: 0.9718 - val_accuracy: 0.8163 - lr: 1.0000e-04\n",
      "Epoch 3/20\n",
      "205/205 [==============================] - 120s 589ms/step - loss: 0.5182 - accuracy: 0.8953 - val_loss: 0.8182 - val_accuracy: 0.8011 - lr: 1.0000e-04\n",
      "Epoch 4/20\n",
      "205/205 [==============================] - 125s 614ms/step - loss: 0.4885 - accuracy: 0.9020 - val_loss: 0.7274 - val_accuracy: 0.8337 - lr: 1.0000e-04\n",
      "Epoch 5/20\n",
      "205/205 [==============================] - 128s 627ms/step - loss: 0.4541 - accuracy: 0.9092 - val_loss: 0.6393 - val_accuracy: 0.8586 - lr: 1.0000e-04\n",
      "Epoch 6/20\n",
      "205/205 [==============================] - 129s 633ms/step - loss: 0.4345 - accuracy: 0.9137 - val_loss: 0.5176 - val_accuracy: 0.8998 - lr: 1.0000e-04\n",
      "Epoch 7/20\n",
      "205/205 [==============================] - 124s 610ms/step - loss: 0.4088 - accuracy: 0.9189 - val_loss: 0.4860 - val_accuracy: 0.9054 - lr: 1.0000e-04\n",
      "Epoch 8/20\n",
      "205/205 [==============================] - 130s 636ms/step - loss: 0.3949 - accuracy: 0.9216 - val_loss: 0.5816 - val_accuracy: 0.8856 - lr: 1.0000e-04\n",
      "Epoch 9/20\n",
      "205/205 [==============================] - 122s 597ms/step - loss: 0.3846 - accuracy: 0.9236 - val_loss: 0.8800 - val_accuracy: 0.8103 - lr: 1.0000e-04\n",
      "Epoch 10/20\n",
      "205/205 [==============================] - 126s 615ms/step - loss: 0.3464 - accuracy: 0.9316 - val_loss: 0.4887 - val_accuracy: 0.9054 - lr: 5.0000e-05\n",
      "Epoch 11/20\n",
      "205/205 [==============================] - 125s 613ms/step - loss: 0.3378 - accuracy: 0.9334 - val_loss: 0.3878 - val_accuracy: 0.9241 - lr: 5.0000e-05\n",
      "Epoch 12/20\n",
      "205/205 [==============================] - 120s 589ms/step - loss: 0.3319 - accuracy: 0.9345 - val_loss: 0.4085 - val_accuracy: 0.9203 - lr: 5.0000e-05\n",
      "Epoch 13/20\n",
      "205/205 [==============================] - ETA: 0s - loss: 0.3263 - accuracy: 0.9357"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Input \u001b[0;32mIn [1]\u001b[0m, in \u001b[0;36m<cell line: 126>\u001b[0;34m()\u001b[0m\n\u001b[1;32m    123\u001b[0m reduce_lr \u001b[38;5;241m=\u001b[39m ReduceLROnPlateau(monitor\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mval_loss\u001b[39m\u001b[38;5;124m'\u001b[39m, factor\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m0.5\u001b[39m, patience\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m2\u001b[39m, min_lr\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m1e-6\u001b[39m)\n\u001b[1;32m    125\u001b[0m \u001b[38;5;66;03m# Model training with data augmentation and regularization\u001b[39;00m\n\u001b[0;32m--> 126\u001b[0m history_segmentation \u001b[38;5;241m=\u001b[39m \u001b[43munet_resnet50\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfit\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    127\u001b[0m \u001b[43m    \u001b[49m\u001b[43mtrain_gen_segmentation\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    128\u001b[0m \u001b[43m    \u001b[49m\u001b[43msteps_per_epoch\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mlen\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43mtrain_df\u001b[49m\u001b[43m)\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m/\u001b[39;49m\u001b[38;5;241;43m/\u001b[39;49m\u001b[43m \u001b[49m\u001b[38;5;241;43m32\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[1;32m    129\u001b[0m \u001b[43m    \u001b[49m\u001b[43mvalidation_data\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mval_gen_segmentation\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    130\u001b[0m \u001b[43m    \u001b[49m\u001b[43mvalidation_steps\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mlen\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43mval_df\u001b[49m\u001b[43m)\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m/\u001b[39;49m\u001b[38;5;241;43m/\u001b[39;49m\u001b[43m \u001b[49m\u001b[38;5;241;43m32\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[1;32m    131\u001b[0m \u001b[43m    \u001b[49m\u001b[43mepochs\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m20\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[1;32m    132\u001b[0m \u001b[43m    \u001b[49m\u001b[43mcallbacks\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m[\u001b[49m\u001b[43mearly_stopping\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mreduce_lr\u001b[49m\u001b[43m]\u001b[49m\n\u001b[1;32m    133\u001b[0m \u001b[43m)\u001b[49m\n\u001b[1;32m    135\u001b[0m \u001b[38;5;66;03m# Evaluate the model on the test set with augmentation\u001b[39;00m\n\u001b[1;32m    136\u001b[0m test_results_segmentation \u001b[38;5;241m=\u001b[39m unet_resnet50\u001b[38;5;241m.\u001b[39mevaluate(test_gen_segmentation, steps\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mlen\u001b[39m(test_df) \u001b[38;5;241m/\u001b[39m\u001b[38;5;241m/\u001b[39m \u001b[38;5;241m32\u001b[39m)\n",
      "File \u001b[0;32m/apps/tensorflow/2.7.0/lib/python3.9/site-packages/keras/utils/traceback_utils.py:64\u001b[0m, in \u001b[0;36mfilter_traceback.<locals>.error_handler\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m     62\u001b[0m filtered_tb \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[1;32m     63\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m---> 64\u001b[0m   \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mfn\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     65\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mException\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m e:  \u001b[38;5;66;03m# pylint: disable=broad-except\u001b[39;00m\n\u001b[1;32m     66\u001b[0m   filtered_tb \u001b[38;5;241m=\u001b[39m _process_traceback_frames(e\u001b[38;5;241m.\u001b[39m__traceback__)\n",
      "File \u001b[0;32m/apps/tensorflow/2.7.0/lib/python3.9/site-packages/keras/engine/training.py:1252\u001b[0m, in \u001b[0;36mModel.fit\u001b[0;34m(self, x, y, batch_size, epochs, verbose, callbacks, validation_split, validation_data, shuffle, class_weight, sample_weight, initial_epoch, steps_per_epoch, validation_steps, validation_batch_size, validation_freq, max_queue_size, workers, use_multiprocessing)\u001b[0m\n\u001b[1;32m   1238\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mgetattr\u001b[39m(\u001b[38;5;28mself\u001b[39m, \u001b[38;5;124m'\u001b[39m\u001b[38;5;124m_eval_data_handler\u001b[39m\u001b[38;5;124m'\u001b[39m, \u001b[38;5;28;01mNone\u001b[39;00m) \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[1;32m   1239\u001b[0m   \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_eval_data_handler \u001b[38;5;241m=\u001b[39m data_adapter\u001b[38;5;241m.\u001b[39mget_data_handler(\n\u001b[1;32m   1240\u001b[0m       x\u001b[38;5;241m=\u001b[39mval_x,\n\u001b[1;32m   1241\u001b[0m       y\u001b[38;5;241m=\u001b[39mval_y,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m   1250\u001b[0m       model\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mself\u001b[39m,\n\u001b[1;32m   1251\u001b[0m       steps_per_execution\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_steps_per_execution)\n\u001b[0;32m-> 1252\u001b[0m val_logs \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mevaluate\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m   1253\u001b[0m \u001b[43m    \u001b[49m\u001b[43mx\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mval_x\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1254\u001b[0m \u001b[43m    \u001b[49m\u001b[43my\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mval_y\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1255\u001b[0m \u001b[43m    \u001b[49m\u001b[43msample_weight\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mval_sample_weight\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1256\u001b[0m \u001b[43m    \u001b[49m\u001b[43mbatch_size\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mvalidation_batch_size\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;129;43;01mor\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mbatch_size\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1257\u001b[0m \u001b[43m    \u001b[49m\u001b[43msteps\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mvalidation_steps\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1258\u001b[0m \u001b[43m    \u001b[49m\u001b[43mcallbacks\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mcallbacks\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1259\u001b[0m \u001b[43m    \u001b[49m\u001b[43mmax_queue_size\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mmax_queue_size\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1260\u001b[0m \u001b[43m    \u001b[49m\u001b[43mworkers\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mworkers\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1261\u001b[0m \u001b[43m    \u001b[49m\u001b[43muse_multiprocessing\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43muse_multiprocessing\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1262\u001b[0m \u001b[43m    \u001b[49m\u001b[43mreturn_dict\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mTrue\u001b[39;49;00m\u001b[43m,\u001b[49m\n\u001b[1;32m   1263\u001b[0m \u001b[43m    \u001b[49m\u001b[43m_use_cached_eval_dataset\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mTrue\u001b[39;49;00m\u001b[43m)\u001b[49m\n\u001b[1;32m   1264\u001b[0m val_logs \u001b[38;5;241m=\u001b[39m {\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mval_\u001b[39m\u001b[38;5;124m'\u001b[39m \u001b[38;5;241m+\u001b[39m name: val \u001b[38;5;28;01mfor\u001b[39;00m name, val \u001b[38;5;129;01min\u001b[39;00m val_logs\u001b[38;5;241m.\u001b[39mitems()}\n\u001b[1;32m   1265\u001b[0m epoch_logs\u001b[38;5;241m.\u001b[39mupdate(val_logs)\n",
      "File \u001b[0;32m/apps/tensorflow/2.7.0/lib/python3.9/site-packages/keras/utils/traceback_utils.py:64\u001b[0m, in \u001b[0;36mfilter_traceback.<locals>.error_handler\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m     62\u001b[0m filtered_tb \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[1;32m     63\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m---> 64\u001b[0m   \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mfn\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     65\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mException\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m e:  \u001b[38;5;66;03m# pylint: disable=broad-except\u001b[39;00m\n\u001b[1;32m     66\u001b[0m   filtered_tb \u001b[38;5;241m=\u001b[39m _process_traceback_frames(e\u001b[38;5;241m.\u001b[39m__traceback__)\n",
      "File \u001b[0;32m/apps/tensorflow/2.7.0/lib/python3.9/site-packages/keras/engine/training.py:1537\u001b[0m, in \u001b[0;36mModel.evaluate\u001b[0;34m(self, x, y, batch_size, verbose, sample_weight, steps, callbacks, max_queue_size, workers, use_multiprocessing, return_dict, **kwargs)\u001b[0m\n\u001b[1;32m   1535\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m tf\u001b[38;5;241m.\u001b[39mprofiler\u001b[38;5;241m.\u001b[39mexperimental\u001b[38;5;241m.\u001b[39mTrace(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mtest\u001b[39m\u001b[38;5;124m'\u001b[39m, step_num\u001b[38;5;241m=\u001b[39mstep, _r\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m1\u001b[39m):\n\u001b[1;32m   1536\u001b[0m   callbacks\u001b[38;5;241m.\u001b[39mon_test_batch_begin(step)\n\u001b[0;32m-> 1537\u001b[0m   tmp_logs \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mtest_function\u001b[49m\u001b[43m(\u001b[49m\u001b[43miterator\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1538\u001b[0m   \u001b[38;5;28;01mif\u001b[39;00m data_handler\u001b[38;5;241m.\u001b[39mshould_sync:\n\u001b[1;32m   1539\u001b[0m     context\u001b[38;5;241m.\u001b[39masync_wait()\n",
      "File \u001b[0;32m/apps/tensorflow/2.7.0/lib/python3.9/site-packages/tensorflow/python/util/traceback_utils.py:150\u001b[0m, in \u001b[0;36mfilter_traceback.<locals>.error_handler\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    148\u001b[0m filtered_tb \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[1;32m    149\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m--> 150\u001b[0m   \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mfn\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    151\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mException\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m e:\n\u001b[1;32m    152\u001b[0m   filtered_tb \u001b[38;5;241m=\u001b[39m _process_traceback_frames(e\u001b[38;5;241m.\u001b[39m__traceback__)\n",
      "File \u001b[0;32m/apps/tensorflow/2.7.0/lib/python3.9/site-packages/tensorflow/python/eager/def_function.py:910\u001b[0m, in \u001b[0;36mFunction.__call__\u001b[0;34m(self, *args, **kwds)\u001b[0m\n\u001b[1;32m    907\u001b[0m compiler \u001b[38;5;241m=\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mxla\u001b[39m\u001b[38;5;124m\"\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_jit_compile \u001b[38;5;28;01melse\u001b[39;00m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mnonXla\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    909\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m OptionalXlaContext(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_jit_compile):\n\u001b[0;32m--> 910\u001b[0m   result \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_call\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwds\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    912\u001b[0m new_tracing_count \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mexperimental_get_tracing_count()\n\u001b[1;32m    913\u001b[0m without_tracing \u001b[38;5;241m=\u001b[39m (tracing_count \u001b[38;5;241m==\u001b[39m new_tracing_count)\n",
      "File \u001b[0;32m/apps/tensorflow/2.7.0/lib/python3.9/site-packages/tensorflow/python/eager/def_function.py:949\u001b[0m, in \u001b[0;36mFunction._call\u001b[0;34m(self, *args, **kwds)\u001b[0m\n\u001b[1;32m    946\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_lock\u001b[38;5;241m.\u001b[39mrelease()\n\u001b[1;32m    947\u001b[0m \u001b[38;5;66;03m# In this case we have not created variables on the first call. So we can\u001b[39;00m\n\u001b[1;32m    948\u001b[0m \u001b[38;5;66;03m# run the first trace but we should fail if variables are created.\u001b[39;00m\n\u001b[0;32m--> 949\u001b[0m results \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_stateful_fn\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwds\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    950\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_created_variables \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m ALLOW_DYNAMIC_VARIABLE_CREATION:\n\u001b[1;32m    951\u001b[0m   \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mCreating variables on a non-first call to a function\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    952\u001b[0m                    \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m decorated with tf.function.\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n",
      "File \u001b[0;32m/apps/tensorflow/2.7.0/lib/python3.9/site-packages/tensorflow/python/eager/function.py:3130\u001b[0m, in \u001b[0;36mFunction.__call__\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   3127\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_lock:\n\u001b[1;32m   3128\u001b[0m   (graph_function,\n\u001b[1;32m   3129\u001b[0m    filtered_flat_args) \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_maybe_define_function(args, kwargs)\n\u001b[0;32m-> 3130\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mgraph_function\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_call_flat\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m   3131\u001b[0m \u001b[43m    \u001b[49m\u001b[43mfiltered_flat_args\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcaptured_inputs\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mgraph_function\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mcaptured_inputs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m/apps/tensorflow/2.7.0/lib/python3.9/site-packages/tensorflow/python/eager/function.py:1959\u001b[0m, in \u001b[0;36mConcreteFunction._call_flat\u001b[0;34m(self, args, captured_inputs, cancellation_manager)\u001b[0m\n\u001b[1;32m   1955\u001b[0m possible_gradient_type \u001b[38;5;241m=\u001b[39m gradients_util\u001b[38;5;241m.\u001b[39mPossibleTapeGradientTypes(args)\n\u001b[1;32m   1956\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m (possible_gradient_type \u001b[38;5;241m==\u001b[39m gradients_util\u001b[38;5;241m.\u001b[39mPOSSIBLE_GRADIENT_TYPES_NONE\n\u001b[1;32m   1957\u001b[0m     \u001b[38;5;129;01mand\u001b[39;00m executing_eagerly):\n\u001b[1;32m   1958\u001b[0m   \u001b[38;5;66;03m# No tape is watching; skip to running the function.\u001b[39;00m\n\u001b[0;32m-> 1959\u001b[0m   \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_build_call_outputs(\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_inference_function\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mcall\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m   1960\u001b[0m \u001b[43m      \u001b[49m\u001b[43mctx\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcancellation_manager\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mcancellation_manager\u001b[49m\u001b[43m)\u001b[49m)\n\u001b[1;32m   1961\u001b[0m forward_backward \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_select_forward_and_backward_functions(\n\u001b[1;32m   1962\u001b[0m     args,\n\u001b[1;32m   1963\u001b[0m     possible_gradient_type,\n\u001b[1;32m   1964\u001b[0m     executing_eagerly)\n\u001b[1;32m   1965\u001b[0m forward_function, args_with_tangents \u001b[38;5;241m=\u001b[39m forward_backward\u001b[38;5;241m.\u001b[39mforward()\n",
      "File \u001b[0;32m/apps/tensorflow/2.7.0/lib/python3.9/site-packages/tensorflow/python/eager/function.py:598\u001b[0m, in \u001b[0;36m_EagerDefinedFunction.call\u001b[0;34m(self, ctx, args, cancellation_manager)\u001b[0m\n\u001b[1;32m    596\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m _InterpolateFunctionError(\u001b[38;5;28mself\u001b[39m):\n\u001b[1;32m    597\u001b[0m   \u001b[38;5;28;01mif\u001b[39;00m cancellation_manager \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[0;32m--> 598\u001b[0m     outputs \u001b[38;5;241m=\u001b[39m \u001b[43mexecute\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mexecute\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    599\u001b[0m \u001b[43m        \u001b[49m\u001b[38;5;28;43mstr\u001b[39;49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43msignature\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mname\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    600\u001b[0m \u001b[43m        \u001b[49m\u001b[43mnum_outputs\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_num_outputs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    601\u001b[0m \u001b[43m        \u001b[49m\u001b[43minputs\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    602\u001b[0m \u001b[43m        \u001b[49m\u001b[43mattrs\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mattrs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    603\u001b[0m \u001b[43m        \u001b[49m\u001b[43mctx\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mctx\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    604\u001b[0m   \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m    605\u001b[0m     outputs \u001b[38;5;241m=\u001b[39m execute\u001b[38;5;241m.\u001b[39mexecute_with_cancellation(\n\u001b[1;32m    606\u001b[0m         \u001b[38;5;28mstr\u001b[39m(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39msignature\u001b[38;5;241m.\u001b[39mname),\n\u001b[1;32m    607\u001b[0m         num_outputs\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_num_outputs,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    610\u001b[0m         ctx\u001b[38;5;241m=\u001b[39mctx,\n\u001b[1;32m    611\u001b[0m         cancellation_manager\u001b[38;5;241m=\u001b[39mcancellation_manager)\n",
      "File \u001b[0;32m/apps/tensorflow/2.7.0/lib/python3.9/site-packages/tensorflow/python/eager/execute.py:58\u001b[0m, in \u001b[0;36mquick_execute\u001b[0;34m(op_name, num_outputs, inputs, attrs, ctx, name)\u001b[0m\n\u001b[1;32m     56\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m     57\u001b[0m   ctx\u001b[38;5;241m.\u001b[39mensure_initialized()\n\u001b[0;32m---> 58\u001b[0m   tensors \u001b[38;5;241m=\u001b[39m \u001b[43mpywrap_tfe\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mTFE_Py_Execute\u001b[49m\u001b[43m(\u001b[49m\u001b[43mctx\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_handle\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdevice_name\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mop_name\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m     59\u001b[0m \u001b[43m                                      \u001b[49m\u001b[43minputs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mattrs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mnum_outputs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     60\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m core\u001b[38;5;241m.\u001b[39m_NotOkStatusException \u001b[38;5;28;01mas\u001b[39;00m e:\n\u001b[1;32m     61\u001b[0m   \u001b[38;5;28;01mif\u001b[39;00m name \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "import os\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import cv2\n",
    "import tensorflow as tf\n",
    "from tensorflow.keras.layers import Input, Conv2D, UpSampling2D, concatenate\n",
    "from tensorflow.keras.models import Model\n",
    "from tensorflow.keras.applications import ResNet50\n",
    "from tensorflow.keras.optimizers import Adam\n",
    "from tensorflow.keras.preprocessing.image import ImageDataGenerator\n",
    "from tensorflow.keras.callbacks import EarlyStopping, ReduceLROnPlateau\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "# TensorFlow GPU configuration\n",
    "physical_devices = tf.config.list_physical_devices('GPU')\n",
    "if len(physical_devices) > 0:\n",
    "    tf.config.experimental.set_memory_growth(physical_devices[0], True)\n",
    "    print(\"Using GPU:\", physical_devices[0])\n",
    "else:\n",
    "    print(\"No GPU found, using CPU\")\n",
    "\n",
    "# Set up paths and categories\n",
    "base_data_dir = '/blue/srampazzi/vi.gade/cov/covid'\n",
    "categories = ['COVID', 'Lung_Opacity', 'Normal', 'Viral_Pneumonia']\n",
    "\n",
    "# Load metadata and preprocess\n",
    "all_metadata = pd.DataFrame()\n",
    "for category in categories:\n",
    "    path = f'{base_data_dir}/{category}.metadata.xlsx'\n",
    "    df = pd.read_excel(path, usecols=['FILE NAME', 'FORMAT', 'SIZE'])\n",
    "    df['label'] = category\n",
    "    df['image_path'] = df['FILE NAME'].apply(lambda x: f'{base_data_dir}/{category}/images/{x}.png')\n",
    "    df['mask_path'] = df['FILE NAME'].apply(lambda x: f'{base_data_dir}/{category}/masks/{x}.png')\n",
    "    df = df[df['image_path'].apply(os.path.exists)]  # Ensure file exists\n",
    "    all_metadata = pd.concat([all_metadata, df], ignore_index=True)\n",
    "\n",
    "# Data splitting\n",
    "train_df, temp_df = train_test_split(all_metadata, test_size=0.4, random_state=42)\n",
    "val_df, test_df = train_test_split(temp_df, test_size=0.5, random_state=42)\n",
    "\n",
    "# Data augmentation\n",
    "datagen = ImageDataGenerator(\n",
    "    rotation_range=20,\n",
    "    width_shift_range=0.2,\n",
    "    height_shift_range=0.2,\n",
    "    shear_range=0.2,\n",
    "    zoom_range=0.2,\n",
    "    horizontal_flip=True,\n",
    "    fill_mode='nearest'\n",
    ")\n",
    "\n",
    "# Data generator function with data augmentation and masks\n",
    "def data_generator_segmentation(df, batch_size=32):\n",
    "    while True:\n",
    "        batch_paths = df.sample(n=batch_size)\n",
    "        batch_input = []\n",
    "        batch_output = []\n",
    "        for _, row in batch_paths.iterrows():\n",
    "            image = cv2.imread(row['image_path'], cv2.IMREAD_COLOR)\n",
    "            mask = cv2.imread(row['mask_path'], cv2.IMREAD_GRAYSCALE)  # Load the mask\n",
    "            if mask is not None:  # Ensure mask is loaded correctly\n",
    "                image = cv2.resize(image, (256, 256))\n",
    "                mask = cv2.resize(mask, (128, 128))  # Resize mask to match output shape\n",
    "                image = image / 255.0\n",
    "                mask = mask / 255.0\n",
    "                mask = np.round(mask).astype(np.float32)  # Ensure mask is binary and float32\n",
    "                image = datagen.random_transform(image)\n",
    "                batch_input.append(image)\n",
    "                batch_output.append(mask.reshape(128, 128, 1))  # Reshape mask to match output dimensions\n",
    "        batch_x = np.array(batch_input)\n",
    "        batch_y = np.array(batch_output)\n",
    "        yield batch_x, batch_y\n",
    "\n",
    "# Setup data generators with data augmentation and masks\n",
    "train_gen_segmentation = data_generator_segmentation(train_df, batch_size=32)\n",
    "val_gen_segmentation = data_generator_segmentation(val_df, batch_size=32)\n",
    "test_gen_segmentation = data_generator_segmentation(test_df, batch_size=32)\n",
    "\n",
    "# Improved U-Net model with ResNet50 encoder and U-Net decoder\n",
    "def build_unet_resnet50(input_shape):\n",
    "    inputs = Input(shape=input_shape)\n",
    "\n",
    "    # Encoder: ResNet50\n",
    "    base_model = ResNet50(weights='imagenet', include_top=False, input_tensor=inputs)\n",
    "    skip_connection_names = ['conv1_relu', 'conv2_block3_out', 'conv3_block4_out', 'conv4_block6_out']\n",
    "    layers = [base_model.get_layer(name).output for name in skip_connection_names]\n",
    "\n",
    "    # Decoder\n",
    "    x = base_model.output\n",
    "    num_filters = 256\n",
    "    for i in range(len(layers)):\n",
    "        x = UpSampling2D()(x)\n",
    "        x = Conv2D(num_filters // (2 ** i), (3, 3), activation='relu', padding='same')(x)\n",
    "        x = concatenate([x, layers[-(i + 1)]])\n",
    "        x = Conv2D(num_filters // (2 ** i), (3, 3), activation='relu', padding='same')(x)\n",
    "\n",
    "    outputs = Conv2D(1, (1, 1), activation='sigmoid')(x)  # Use sigmoid activation for binary segmentation\n",
    "    model = Model(inputs, outputs)\n",
    "    return model\n",
    "\n",
    "input_shape = (256, 256, 3)\n",
    "unet_resnet50 = build_unet_resnet50(input_shape)\n",
    "\n",
    "# Define the combined loss function\n",
    "def dice_loss(y_true, y_pred):\n",
    "    y_true_f = tf.keras.backend.flatten(y_true)\n",
    "    y_pred_f = tf.keras.backend.flatten(y_pred)\n",
    "    intersection = tf.keras.backend.sum(y_true_f * y_pred_f)\n",
    "    return 1 - (2. * intersection + 1) / (tf.keras.backend.sum(y_true_f) + tf.keras.backend.sum(y_pred_f) + 1)\n",
    "\n",
    "def combined_loss(y_true, y_pred):\n",
    "    y_true = tf.cast(y_true, tf.float32)  # Ensure y_true is float32\n",
    "    y_pred = tf.cast(y_pred, tf.float32)  # Ensure y_pred is float32\n",
    "    print(f\"combined_loss: y_true shape: {y_true.shape}, y_pred shape: {y_pred.shape}\")  # Add debug prints\n",
    "    bce = tf.keras.losses.binary_crossentropy(y_true, y_pred)\n",
    "    dice = dice_loss(y_true, y_pred)\n",
    "    return bce + dice\n",
    "\n",
    "unet_resnet50.compile(optimizer=Adam(learning_rate=0.0001), loss=combined_loss, metrics=['accuracy'])\n",
    "\n",
    "# Callbacks for early stopping and learning rate reduction\n",
    "early_stopping = EarlyStopping(monitor='val_loss', patience=5, restore_best_weights=True)\n",
    "reduce_lr = ReduceLROnPlateau(monitor='val_loss', factor=0.5, patience=2, min_lr=1e-6)\n",
    "\n",
    "# Model training with data augmentation and regularization\n",
    "history_segmentation = unet_resnet50.fit(\n",
    "    train_gen_segmentation,\n",
    "    steps_per_epoch=len(train_df) // 32,\n",
    "    validation_data=val_gen_segmentation,\n",
    "    validation_steps=len(val_df) // 32,\n",
    "    epochs=20,\n",
    "    callbacks=[early_stopping, reduce_lr]\n",
    ")\n",
    "\n",
    "# Evaluate the model on the test set with augmentation\n",
    "test_results_segmentation = unet_resnet50.evaluate(test_gen_segmentation, steps=len(test_df) // 32)\n",
    "print(f\"Test accuracy with segmentation model: {test_results_segmentation[1]*100:.2f}%\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "27441d4d-cacb-4db8-82bc-a71e13e50bee",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using GPU: PhysicalDevice(name='/physical_device:GPU:0', device_type='GPU')\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-06-16 23:59:50.564483: I tensorflow/core/platform/cpu_feature_guard.cc:151] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations:  SSE4.1 SSE4.2 AVX AVX2 FMA\n",
      "To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
      "2024-06-16 23:59:51.365159: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1525] Created device /job:localhost/replica:0/task:0/device:GPU:0 with 78911 MB memory:  -> device: 0, name: NVIDIA A100-SXM4-80GB, pci bus id: 0000:07:00.0, compute capability: 8.0\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/20\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-06-16 23:59:52.965022: I tensorflow/stream_executor/cuda/cuda_dnn.cc:366] Loaded cuDNN version 8201\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "822/822 [==============================] - 146s 172ms/step - loss: 0.4727 - accuracy: 0.7735 - val_loss: 0.4605 - val_accuracy: 0.7749 - lr: 1.0000e-04\n",
      "Epoch 2/20\n",
      "822/822 [==============================] - 142s 172ms/step - loss: 0.4624 - accuracy: 0.7738 - val_loss: 0.4616 - val_accuracy: 0.7727 - lr: 1.0000e-04\n",
      "Epoch 3/20\n",
      "822/822 [==============================] - 141s 171ms/step - loss: 0.4614 - accuracy: 0.7735 - val_loss: 0.4584 - val_accuracy: 0.7744 - lr: 1.0000e-04\n",
      "Epoch 4/20\n",
      "822/822 [==============================] - 140s 171ms/step - loss: 0.4616 - accuracy: 0.7729 - val_loss: 0.4643 - val_accuracy: 0.7721 - lr: 1.0000e-04\n",
      "Epoch 5/20\n",
      "822/822 [==============================] - 140s 171ms/step - loss: 0.4616 - accuracy: 0.7732 - val_loss: 0.4592 - val_accuracy: 0.7717 - lr: 1.0000e-04\n",
      "Epoch 6/20\n",
      "822/822 [==============================] - 140s 170ms/step - loss: 0.4605 - accuracy: 0.7731 - val_loss: 0.4580 - val_accuracy: 0.7732 - lr: 1.0000e-04\n",
      "Epoch 7/20\n",
      "822/822 [==============================] - 141s 171ms/step - loss: 0.4613 - accuracy: 0.7725 - val_loss: 0.4613 - val_accuracy: 0.7713 - lr: 1.0000e-04\n",
      "Epoch 8/20\n",
      "822/822 [==============================] - 140s 171ms/step - loss: 0.4601 - accuracy: 0.7733 - val_loss: 0.4614 - val_accuracy: 0.7729 - lr: 1.0000e-04\n",
      "Epoch 9/20\n",
      "822/822 [==============================] - 141s 171ms/step - loss: 0.4604 - accuracy: 0.7729 - val_loss: 0.4578 - val_accuracy: 0.7754 - lr: 1.0000e-04\n",
      "Epoch 10/20\n",
      "822/822 [==============================] - 140s 171ms/step - loss: 0.4596 - accuracy: 0.7735 - val_loss: 0.4575 - val_accuracy: 0.7739 - lr: 1.0000e-04\n",
      "Epoch 11/20\n",
      "822/822 [==============================] - 140s 171ms/step - loss: 0.4600 - accuracy: 0.7724 - val_loss: 0.4606 - val_accuracy: 0.7716 - lr: 1.0000e-04\n",
      "Epoch 12/20\n",
      "822/822 [==============================] - 139s 169ms/step - loss: 0.4595 - accuracy: 0.7727 - val_loss: 0.4581 - val_accuracy: 0.7723 - lr: 1.0000e-04\n",
      "Epoch 13/20\n",
      "822/822 [==============================] - 140s 171ms/step - loss: 0.4580 - accuracy: 0.7742 - val_loss: 0.4623 - val_accuracy: 0.7699 - lr: 1.0000e-04\n",
      "Epoch 14/20\n",
      "822/822 [==============================] - 141s 172ms/step - loss: 0.4571 - accuracy: 0.7732 - val_loss: 0.4604 - val_accuracy: 0.7715 - lr: 2.0000e-05\n",
      "Epoch 15/20\n",
      "822/822 [==============================] - 140s 171ms/step - loss: 0.4536 - accuracy: 0.7750 - val_loss: 0.4538 - val_accuracy: 0.7745 - lr: 2.0000e-05\n",
      "Epoch 16/20\n",
      "822/822 [==============================] - 140s 170ms/step - loss: 0.4552 - accuracy: 0.7747 - val_loss: 0.4556 - val_accuracy: 0.7743 - lr: 2.0000e-05\n",
      "Epoch 17/20\n",
      "822/822 [==============================] - 141s 172ms/step - loss: 0.4566 - accuracy: 0.7731 - val_loss: 0.4522 - val_accuracy: 0.7775 - lr: 2.0000e-05\n",
      "Epoch 18/20\n",
      "822/822 [==============================] - 140s 170ms/step - loss: 0.4559 - accuracy: 0.7740 - val_loss: 0.4544 - val_accuracy: 0.7734 - lr: 2.0000e-05\n",
      "Epoch 19/20\n",
      "822/822 [==============================] - 140s 171ms/step - loss: 0.4564 - accuracy: 0.7725 - val_loss: 0.4543 - val_accuracy: 0.7760 - lr: 2.0000e-05\n",
      "Epoch 20/20\n",
      "822/822 [==============================] - 140s 171ms/step - loss: 0.4548 - accuracy: 0.7744 - val_loss: 0.4536 - val_accuracy: 0.7751 - lr: 2.0000e-05\n",
      "274/274 [==============================] - 35s 128ms/step - loss: 0.4567 - accuracy: 0.7746\n",
      "Test accuracy with augmentation and regularization: 77.46%\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import cv2\n",
    "import tensorflow as tf\n",
    "from tensorflow.keras.layers import Input, Conv2D, MaxPooling2D, UpSampling2D, concatenate, Dropout\n",
    "from tensorflow.keras.models import Model\n",
    "from tensorflow.keras.optimizers import Adam\n",
    "from tensorflow.keras.preprocessing.image import ImageDataGenerator\n",
    "from tensorflow.keras.callbacks import EarlyStopping, ReduceLROnPlateau\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "# TensorFlow GPU configuration\n",
    "physical_devices = tf.config.list_physical_devices('GPU')\n",
    "if len(physical_devices) > 0:\n",
    "    tf.config.experimental.set_memory_growth(physical_devices[0], True)\n",
    "    print(\"Using GPU:\", physical_devices[0])\n",
    "else:\n",
    "    print(\"No GPU found, using CPU\")\n",
    "\n",
    "# Set up paths\n",
    "base_data_dir = '/blue/srampazzi/vi.gade/cov/covid'\n",
    "categories = ['COVID', 'Lung_Opacity', 'Normal', 'Viral_Pneumonia']\n",
    "\n",
    "# Load metadata\n",
    "all_metadata = pd.DataFrame()\n",
    "for category in categories:\n",
    "    path = f'{base_data_dir}/{category}.metadata.xlsx'\n",
    "    df = pd.read_excel(path, usecols=['FILE NAME', 'FORMAT', 'SIZE'])\n",
    "    df['label'] = category\n",
    "    df['image_path'] = df['FILE NAME'].apply(lambda x: f'{base_data_dir}/{category}/images/{x}.png')\n",
    "    df['mask_path'] = df['FILE NAME'].apply(lambda x: f'{base_data_dir}/{category}/masks/{x}.png')\n",
    "    df = df[df['image_path'].apply(os.path.exists)]  # Ensure file exists\n",
    "    all_metadata = pd.concat([all_metadata, df], ignore_index=True)\n",
    "\n",
    "# Data splitting\n",
    "train_df, temp_df = train_test_split(all_metadata, test_size=0.4, random_state=42)\n",
    "val_df, test_df = train_test_split(temp_df, test_size=0.5, random_state=42)\n",
    "\n",
    "# Data augmentation\n",
    "datagen = ImageDataGenerator(\n",
    "    rotation_range=20,\n",
    "    width_shift_range=0.2,\n",
    "    height_shift_range=0.2,\n",
    "    shear_range=0.2,\n",
    "    zoom_range=0.2,\n",
    "    horizontal_flip=True,\n",
    "    fill_mode='nearest'\n",
    ")\n",
    "\n",
    "# Data generator function for segmentation\n",
    "def data_generator_segmentation(df, batch_size=8):\n",
    "    while True:\n",
    "        batch_paths = df.sample(n=batch_size)\n",
    "        batch_input = []\n",
    "        batch_output = []\n",
    "        for _, row in batch_paths.iterrows():\n",
    "            image = cv2.imread(row['image_path'], cv2.IMREAD_COLOR)\n",
    "            mask = cv2.imread(row['mask_path'], cv2.IMREAD_GRAYSCALE)  # Load the mask\n",
    "            if mask is not None:  # Ensure mask is loaded correctly\n",
    "                image = cv2.resize(image, (256, 256))\n",
    "                mask = cv2.resize(mask, (256, 256))\n",
    "                image = image / 255.0\n",
    "                mask = mask / 255.0\n",
    "                image = datagen.random_transform(image)\n",
    "                mask = np.expand_dims(mask, axis=-1)  # Expand mask dimensions\n",
    "                mask = datagen.random_transform(mask)\n",
    "                batch_input.append(image)\n",
    "                batch_output.append(mask)\n",
    "        batch_x = np.array(batch_input)\n",
    "        batch_y = np.array(batch_output)\n",
    "        yield batch_x, batch_y\n",
    "\n",
    "# Setup data generators\n",
    "train_gen_segmentation = data_generator_segmentation(train_df, batch_size=8)\n",
    "val_gen_segmentation = data_generator_segmentation(val_df, batch_size=8)\n",
    "test_gen_segmentation = data_generator_segmentation(test_df, batch_size=8)\n",
    "\n",
    "# Define U-Net model\n",
    "def unet_model(input_size=(256, 256, 3)):\n",
    "    inputs = Input(input_size)\n",
    "    c1 = Conv2D(64, (3, 3), activation='relu', padding='same')(inputs)\n",
    "    c1 = Conv2D(64, (3, 3), activation='relu', padding='same')(c1)\n",
    "    p1 = MaxPooling2D((2, 2))(c1)\n",
    "\n",
    "    c2 = Conv2D(128, (3, 3), activation='relu', padding='same')(p1)\n",
    "    c2 = Conv2D(128, (3, 3), activation='relu', padding='same')(c2)\n",
    "    p2 = MaxPooling2D((2, 2))(c2)\n",
    "\n",
    "    c3 = Conv2D(256, (3, 3), activation='relu', padding='same')(p2)\n",
    "    c3 = Conv2D(256, (3, 3), activation='relu', padding='same')(c3)\n",
    "    p3 = MaxPooling2D((2, 2))(c3)\n",
    "\n",
    "    c4 = Conv2D(512, (3, 3), activation='relu', padding='same')(p3)\n",
    "    c4 = Conv2D(512, (3, 3), activation='relu', padding='same')(c4)\n",
    "    p4 = MaxPooling2D(pool_size=(2, 2))(c4)\n",
    "\n",
    "    c5 = Conv2D(1024, (3, 3), activation='relu', padding='same')(p4)\n",
    "    c5 = Conv2D(1024, (3, 3), activation='relu', padding='same')(c5)\n",
    "\n",
    "    u6 = UpSampling2D(size=(2, 2))(c5)\n",
    "    u6 = concatenate([u6, c4], axis=3)\n",
    "    c6 = Conv2D(512, (3, 3), activation='relu', padding='same')(u6)\n",
    "    c6 = Conv2D(512, (3, 3), activation='relu', padding='same')(c6)\n",
    "\n",
    "    u7 = UpSampling2D(size=(2, 2))(c6)\n",
    "    u7 = concatenate([u7, c3], axis=3)\n",
    "    c7 = Conv2D(256, (3, 3), activation='relu', padding='same')(u7)\n",
    "    c7 = Conv2D(256, (3, 3), activation='relu', padding='same')(c7)\n",
    "\n",
    "    u8 = UpSampling2D(size=(2, 2))(c7)\n",
    "    u8 = concatenate([u8, c2], axis=3)\n",
    "    c8 = Conv2D(128, (3, 3), activation='relu', padding='same')(u8)\n",
    "    c8 = Conv2D(128, (3, 3), activation='relu', padding='same')(c8)\n",
    "\n",
    "    u9 = UpSampling2D(size=(2, 2))(c8)\n",
    "    u9 = concatenate([u9, c1], axis=3)\n",
    "    c9 = Conv2D(64, (3, 3), activation='relu', padding='same')(u9)\n",
    "    c9 = Conv2D(64, (3, 3), activation='relu', padding='same')(c9)\n",
    "\n",
    "    outputs = Conv2D(1, (1, 1), activation='sigmoid')(c9)\n",
    "\n",
    "    model = Model(inputs=[inputs], outputs=[outputs])\n",
    "\n",
    "    return model\n",
    "\n",
    "# Build and compile the U-Net model\n",
    "unet = unet_model()\n",
    "unet.compile(optimizer=Adam(learning_rate=0.0001), loss='binary_crossentropy', metrics=['accuracy'])\n",
    "\n",
    "# Callbacks for early stopping and learning rate reduction\n",
    "early_stopping = EarlyStopping(monitor='val_loss', patience=5, restore_best_weights=True)\n",
    "reduce_lr = ReduceLROnPlateau(monitor='val_loss', factor=0.2, patience=3, min_lr=0.00001)\n",
    "\n",
    "# Model training with data augmentation and regularization\n",
    "history_segmentation = unet.fit(\n",
    "    train_gen_segmentation,\n",
    "    steps_per_epoch=len(train_df) // 8,\n",
    "    validation_data=val_gen_segmentation,\n",
    "    validation_steps=len(val_df) // 8,\n",
    "    epochs=20,\n",
    "    callbacks=[early_stopping, reduce_lr]\n",
    ")\n",
    "\n",
    "# Evaluate the model on the test set with augmentation\n",
    "test_results_segmentation = unet.evaluate(test_gen_segmentation, steps=len(test_df) // 8)\n",
    "print(f\"Test accuracy with augmentation and regularization: {test_results_segmentation[1]*100:.2f}%\")\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Tensorflow-2.7.0",
   "language": "python",
   "name": "tensorflow-2.7.0"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
