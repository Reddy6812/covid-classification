{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "57eff051-9af7-4f07-b90b-262ac5e7c303",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using GPU: PhysicalDevice(name='/physical_device:GPU:0', device_type='GPU')\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-06-25 00:28:55.792304: I tensorflow/core/platform/cpu_feature_guard.cc:151] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations:  SSE4.1 SSE4.2 AVX AVX2 FMA\n",
      "To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
      "2024-06-25 00:28:56.621435: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1525] Created device /job:localhost/replica:0/task:0/device:GPU:0 with 78902 MB memory:  -> device: 0, name: NVIDIA A100-SXM4-80GB, pci bus id: 0000:87:00.0, compute capability: 8.0\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/12\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-06-25 00:29:03.256098: I tensorflow/stream_executor/cuda/cuda_dnn.cc:366] Loaded cuDNN version 8201\n",
      "2024-06-25 00:29:05.127090: I tensorflow/stream_executor/cuda/cuda_blas.cc:1774] TensorFloat-32 will be used for the matrix multiplication. This will only be logged once.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "205/205 [==============================] - ETA: 0s - loss: 735.8639 - accuracy: 0.7326 - precision: 0.7501 - recall: 0.6904"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/apps/tensorflow/2.7.0/lib/python3.9/site-packages/keras/engine/functional.py:1410: CustomMaskWarning: Custom mask layers require a config and must override get_config. When loading, the custom mask layer must be passed to the custom_objects argument.\n",
      "  layer_config = serialize_layer_fn(layer)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "205/205 [==============================] - 127s 581ms/step - loss: 735.8639 - accuracy: 0.7326 - precision: 0.7501 - recall: 0.6904 - val_loss: 24.9828 - val_accuracy: 0.5501 - val_precision: 0.5614 - val_recall: 0.1429 - lr: 1.0000e-04\n",
      "Epoch 2/12\n",
      "205/205 [==============================] - 117s 575ms/step - loss: 21.9331 - accuracy: 0.8328 - precision: 0.8616 - recall: 0.7864 - val_loss: 20.8941 - val_accuracy: 0.5538 - val_precision: 0.0000e+00 - val_recall: 0.0000e+00 - lr: 1.0000e-04\n",
      "Epoch 3/12\n",
      "205/205 [==============================] - 117s 575ms/step - loss: 18.5449 - accuracy: 0.8794 - precision: 0.8973 - recall: 0.8538 - val_loss: 18.4492 - val_accuracy: 0.3626 - val_precision: 0.3613 - val_recall: 0.3244 - lr: 1.0000e-04\n",
      "Epoch 4/12\n",
      "205/205 [==============================] - 117s 575ms/step - loss: 16.8467 - accuracy: 0.8910 - precision: 0.9083 - recall: 0.8715 - val_loss: 17.8620 - val_accuracy: 0.3396 - val_precision: 0.3425 - val_recall: 0.3373 - lr: 1.0000e-04\n",
      "Epoch 5/12\n",
      "205/205 [==============================] - 118s 578ms/step - loss: 15.7835 - accuracy: 0.9099 - precision: 0.9208 - recall: 0.8954 - val_loss: 15.8701 - val_accuracy: 0.6250 - val_precision: 0.6325 - val_recall: 0.6066 - lr: 1.0000e-04\n",
      "Epoch 6/12\n",
      "205/205 [==============================] - 117s 573ms/step - loss: 15.1609 - accuracy: 0.9155 - precision: 0.9242 - recall: 0.9011 - val_loss: 15.1581 - val_accuracy: 0.7973 - val_precision: 0.8035 - val_recall: 0.7872 - lr: 1.0000e-04\n",
      "Epoch 7/12\n",
      "205/205 [==============================] - 117s 574ms/step - loss: 14.7828 - accuracy: 0.9233 - precision: 0.9316 - recall: 0.9090 - val_loss: 14.9613 - val_accuracy: 0.7753 - val_precision: 0.7886 - val_recall: 0.7610 - lr: 1.0000e-04\n",
      "Epoch 8/12\n",
      "205/205 [==============================] - 118s 577ms/step - loss: 14.6567 - accuracy: 0.9215 - precision: 0.9277 - recall: 0.9116 - val_loss: 14.6438 - val_accuracy: 0.9159 - val_precision: 0.9218 - val_recall: 0.8989 - lr: 1.0000e-04\n",
      "Epoch 9/12\n",
      "205/205 [==============================] - 115s 564ms/step - loss: 14.5786 - accuracy: 0.9329 - precision: 0.9411 - recall: 0.9224 - val_loss: 14.6695 - val_accuracy: 0.8961 - val_precision: 0.9091 - val_recall: 0.8778 - lr: 1.0000e-04\n",
      "Epoch 10/12\n",
      "205/205 [==============================] - 114s 560ms/step - loss: 14.5250 - accuracy: 0.9380 - precision: 0.9440 - recall: 0.9299 - val_loss: 14.7130 - val_accuracy: 0.8419 - val_precision: 0.8492 - val_recall: 0.8332 - lr: 1.0000e-04\n",
      "Epoch 11/12\n",
      "205/205 [==============================] - 114s 558ms/step - loss: 14.5432 - accuracy: 0.9377 - precision: 0.9451 - recall: 0.9282 - val_loss: 14.6562 - val_accuracy: 0.8667 - val_precision: 0.8783 - val_recall: 0.8557 - lr: 1.0000e-04\n",
      "Epoch 12/12\n",
      "205/205 [==============================] - 117s 573ms/step - loss: 3.8641 - accuracy: 0.9540 - precision: 0.9580 - recall: 0.9486 - val_loss: 3.4436 - val_accuracy: 0.9545 - val_precision: 0.9570 - val_recall: 0.9504 - lr: 2.0000e-05\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/apps/tensorflow/2.7.0/lib/python3.9/site-packages/keras/backend.py:414: UserWarning: `tf.keras.backend.set_learning_phase` is deprecated and will be removed after 2020-10-11. To update it, simply pass a True/False value to the `training` argument of the `__call__` method of your layer or model.\n",
      "  warnings.warn('`tf.keras.backend.set_learning_phase` is deprecated and '\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "68/68 [==============================] - 28s 419ms/step - loss: 3.4714 - accuracy: 0.9439 - precision: 0.9455 - recall: 0.9403\n",
      "Test accuracy with augmentation and regularization: 94.39%\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-06-25 00:53:00.832516: W tensorflow/python/util/util.cc:368] Sets are not currently considered sequences, but this may change in the future, so consider avoiding using them.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: final_modelj25/assets\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/apps/tensorflow/2.7.0/lib/python3.9/site-packages/keras/engine/functional.py:1410: CustomMaskWarning: Custom mask layers require a config and must override get_config. When loading, the custom mask layer must be passed to the custom_objects argument.\n",
      "  layer_config = serialize_layer_fn(layer)\n",
      "/apps/tensorflow/2.7.0/lib/python3.9/site-packages/keras/saving/saved_model/layer_serialization.py:112: CustomMaskWarning: Custom mask layers require a config and must override get_config. When loading, the custom mask layer must be passed to the custom_objects argument.\n",
      "  return generic_utils.serialize_keras_object(obj)\n"
     ]
    }
   ],
   "source": [
    "#jun 25\n",
    "\n",
    "import os\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import cv2\n",
    "import tensorflow as tf\n",
    "from tensorflow.keras.layers import Input, Flatten, Dense, Dropout\n",
    "from tensorflow.keras.models import Model\n",
    "from tensorflow.keras.applications import ResNet50\n",
    "from tensorflow.keras.optimizers import Adam\n",
    "from tensorflow.keras.preprocessing.image import ImageDataGenerator\n",
    "from tensorflow.keras.callbacks import EarlyStopping, ReduceLROnPlateau, ModelCheckpoint\n",
    "from tensorflow.keras.metrics import Precision, Recall\n",
    "from sklearn.model_selection import train_test_split\n",
    "from tensorflow.keras import backend as K\n",
    "\n",
    "# TensorFlow GPU configuration\n",
    "physical_devices = tf.config.list_physical_devices('GPU')\n",
    "if len(physical_devices) > 0:\n",
    "    tf.config.experimental.set_memory_growth(physical_devices[0], True)\n",
    "    print(\"Using GPU:\", physical_devices[0])\n",
    "else:\n",
    "    print(\"No GPU found, using CPU\")\n",
    "\n",
    "# Set up paths and categories\n",
    "base_data_dir = '/blue/srampazzi/vi.gade/cov/covid'\n",
    "categories = ['COVID', 'Lung_Opacity', 'Normal', 'Viral_Pneumonia']\n",
    "\n",
    "# Load metadata and preprocess\n",
    "all_metadata = pd.DataFrame()\n",
    "for category in categories:\n",
    "    path = f'{base_data_dir}/{category}.metadata.xlsx'\n",
    "    df = pd.read_excel(path, usecols=['FILE NAME', 'FORMAT', 'SIZE'])\n",
    "    df['label'] = category\n",
    "    df['image_path'] = df['FILE NAME'].apply(lambda x: f'{base_data_dir}/{category}/images/{x}.png')\n",
    "    df['mask_path'] = df['FILE NAME'].apply(lambda x: f'{base_data_dir}/{category}/masks/{x}.png')\n",
    "    df = df[df['image_path'].apply(os.path.exists)]  # Ensure file exists\n",
    "    all_metadata = pd.concat([all_metadata, df], ignore_index=True)\n",
    "\n",
    "# Data splitting\n",
    "train_df, temp_df = train_test_split(all_metadata, test_size=0.4, random_state=42)\n",
    "val_df, test_df = train_test_split(temp_df, test_size=0.5, random_state=42)\n",
    "\n",
    "# Data augmentation\n",
    "datagen = ImageDataGenerator(\n",
    "    rotation_range=20,\n",
    "    width_shift_range=0.2,\n",
    "    height_shift_range=0.2,\n",
    "    shear_range=0.2,\n",
    "    zoom_range=0.2,\n",
    "    horizontal_flip=True,\n",
    "    fill_mode='nearest'\n",
    ")\n",
    "\n",
    "# Function to apply mask\n",
    "def apply_mask(image, mask):\n",
    "    mask = cv2.resize(mask, (image.shape[1], image.shape[0]))  # Resize mask to match image size\n",
    "    return cv2.bitwise_and(image, image, mask=mask)\n",
    "\n",
    "# Data generator function with data augmentation and masks\n",
    "def data_generator_augmented_with_masks(df, batch_size=32):\n",
    "    while True:\n",
    "        batch_paths = df.sample(n=batch_size)\n",
    "        batch_input = []\n",
    "        batch_output = []\n",
    "        for _, row in batch_paths.iterrows():\n",
    "            image = cv2.imread(row['image_path'], cv2.IMREAD_COLOR)\n",
    "            mask = cv2.imread(row['mask_path'], cv2.IMREAD_GRAYSCALE)  # Load the mask\n",
    "            if mask is not None:  # Ensure mask is loaded correctly\n",
    "                masked_image = apply_mask(image, mask)  # Apply the mask to the image\n",
    "            else:\n",
    "                masked_image = image\n",
    "            image = cv2.resize(masked_image, (256, 256))\n",
    "            image = image / 255.0\n",
    "            image = datagen.random_transform(image)\n",
    "            batch_input.append(image)\n",
    "            batch_output.append(tf.keras.utils.to_categorical(categories.index(row['label']), num_classes=len(categories)))\n",
    "        batch_x = np.array(batch_input)\n",
    "        batch_y = np.array(batch_output)\n",
    "        yield batch_x, batch_y\n",
    "\n",
    "# Setup data generators with data augmentation and masks\n",
    "train_gen_augmented = data_generator_augmented_with_masks(train_df, batch_size=32)\n",
    "val_gen_augmented = data_generator_augmented_with_masks(val_df, batch_size=32)\n",
    "test_gen_augmented = data_generator_augmented_with_masks(test_df, batch_size=32)\n",
    "\n",
    "# Model building with increased regularization\n",
    "base_model = ResNet50(weights='imagenet', include_top=False, input_tensor=Input(shape=(256, 256, 3)))\n",
    "for layer in base_model.layers[-10:]:\n",
    "    layer.trainable = True  # Fine-tune the last 10 layers\n",
    "\n",
    "# Add custom layers with L1/L2 regularization\n",
    "regularizer = tf.keras.regularizers.l1_l2(l2=0.5)\n",
    "x = Flatten()(base_model.output)\n",
    "x = Dense(1024, activation='relu', kernel_regularizer=regularizer)(x)\n",
    "x = Dropout(0.5)(x)\n",
    "predictions = Dense(len(categories), activation='softmax', kernel_regularizer=regularizer)(x)\n",
    "model = Model(inputs=base_model.input, outputs=predictions)\n",
    "\n",
    "# Compile the model with custom metrics\n",
    "model.compile(optimizer=Adam(learning_rate=0.0001),\n",
    "              loss='categorical_crossentropy',\n",
    "              metrics=['accuracy', Precision(), Recall()])\n",
    "\n",
    "# Callbacks for early stopping, model checkpoint, and learning rate reduction\n",
    "early_stopping = EarlyStopping(monitor='val_loss', patience=5, restore_best_weights=True)\n",
    "reduce_lr = ReduceLROnPlateau(monitor='val_loss', factor=0.2, patience=3, min_lr=0.00001)\n",
    "model_checkpoint = ModelCheckpoint('best_modelj25.h5', save_best_only=True, monitor='val_loss')\n",
    "\n",
    "# Model training with data augmentation and regularization\n",
    "history_augmented = model.fit(\n",
    "    train_gen_augmented,\n",
    "    steps_per_epoch=len(train_df) // 32,\n",
    "    validation_data=val_gen_augmented,\n",
    "    validation_steps=len(val_df) // 32,\n",
    "    epochs=12,\n",
    "    callbacks=[early_stopping, reduce_lr, model_checkpoint]\n",
    ")\n",
    "\n",
    "# Ensure model is in evaluation mode during prediction\n",
    "K.set_learning_phase(0)\n",
    "\n",
    "# Evaluate the model on the test set with augmentation\n",
    "test_results_augmented = model.evaluate(test_gen_augmented, steps=len(test_df) // 32)\n",
    "print(f\"Test accuracy with augmentation and regularization: {test_results_augmented[1]*100:.2f}%\")\n",
    "\n",
    "# Save the model in TensorFlow SavedModel format\n",
    "model.save('final_modelj25')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "8c38ac46-68a2-45ce-8c35-f0918b801c64",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using GPU: PhysicalDevice(name='/physical_device:GPU:0', device_type='GPU')\n",
      "Epoch 1/12\n",
      "205/205 [==============================] - ETA: 0s - loss: 734.8950 - accuracy: 0.7287 - precision_1: 0.7458 - recall_1: 0.6977"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/apps/tensorflow/2.7.0/lib/python3.9/site-packages/keras/engine/functional.py:1410: CustomMaskWarning: Custom mask layers require a config and must override get_config. When loading, the custom mask layer must be passed to the custom_objects argument.\n",
      "  layer_config = serialize_layer_fn(layer)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "205/205 [==============================] - 124s 583ms/step - loss: 734.8950 - accuracy: 0.7287 - precision_1: 0.7458 - recall_1: 0.6977 - val_loss: 23.6558 - val_accuracy: 0.5381 - val_precision_1: 0.5381 - val_recall_1: 0.5381 - lr: 1.0000e-04\n",
      "Epoch 2/12\n",
      "205/205 [==============================] - 118s 579ms/step - loss: 20.9875 - accuracy: 0.8378 - precision_1: 0.8552 - recall_1: 0.8067 - val_loss: 19.8459 - val_accuracy: 0.5680 - val_precision_1: 0.5680 - val_recall_1: 0.5680 - lr: 1.0000e-04\n",
      "Epoch 3/12\n",
      "205/205 [==============================] - 131s 641ms/step - loss: 18.4064 - accuracy: 0.8773 - precision_1: 0.8896 - recall_1: 0.8587 - val_loss: 18.7395 - val_accuracy: 0.5657 - val_precision_1: 0.5657 - val_recall_1: 0.5657 - lr: 1.0000e-04\n",
      "Epoch 4/12\n",
      "205/205 [==============================] - 119s 581ms/step - loss: 16.8845 - accuracy: 0.8942 - precision_1: 0.9071 - recall_1: 0.8739 - val_loss: 16.7422 - val_accuracy: 0.6264 - val_precision_1: 0.6420 - val_recall_1: 0.5951 - lr: 1.0000e-04\n",
      "Epoch 5/12\n",
      "205/205 [==============================] - 118s 580ms/step - loss: 15.9106 - accuracy: 0.8994 - precision_1: 0.9112 - recall_1: 0.8811 - val_loss: 15.8668 - val_accuracy: 0.7445 - val_precision_1: 0.7730 - val_recall_1: 0.7261 - lr: 1.0000e-04\n",
      "Epoch 6/12\n",
      "205/205 [==============================] - 118s 579ms/step - loss: 15.1617 - accuracy: 0.9183 - precision_1: 0.9313 - recall_1: 0.9046 - val_loss: 15.3006 - val_accuracy: 0.7270 - val_precision_1: 0.7389 - val_recall_1: 0.6985 - lr: 1.0000e-04\n",
      "Epoch 7/12\n",
      "205/205 [==============================] - 119s 582ms/step - loss: 14.7870 - accuracy: 0.9155 - precision_1: 0.9252 - recall_1: 0.8994 - val_loss: 14.8597 - val_accuracy: 0.8222 - val_precision_1: 0.8338 - val_recall_1: 0.8070 - lr: 1.0000e-04\n",
      "Epoch 8/12\n",
      "205/205 [==============================] - 117s 572ms/step - loss: 14.6622 - accuracy: 0.9162 - precision_1: 0.9282 - recall_1: 0.9030 - val_loss: 14.9035 - val_accuracy: 0.7564 - val_precision_1: 0.7836 - val_recall_1: 0.7188 - lr: 1.0000e-04\n",
      "Epoch 9/12\n",
      "205/205 [==============================] - 120s 587ms/step - loss: 14.5715 - accuracy: 0.9338 - precision_1: 0.9413 - recall_1: 0.9212 - val_loss: 14.7772 - val_accuracy: 0.8470 - val_precision_1: 0.8553 - val_recall_1: 0.8364 - lr: 1.0000e-04\n",
      "Epoch 10/12\n",
      "205/205 [==============================] - 120s 586ms/step - loss: 14.5345 - accuracy: 0.9354 - precision_1: 0.9438 - recall_1: 0.9238 - val_loss: 14.7620 - val_accuracy: 0.8364 - val_precision_1: 0.8465 - val_recall_1: 0.8286 - lr: 1.0000e-04\n",
      "Epoch 11/12\n",
      "205/205 [==============================] - 116s 567ms/step - loss: 14.5564 - accuracy: 0.9363 - precision_1: 0.9442 - recall_1: 0.9242 - val_loss: 14.7744 - val_accuracy: 0.8539 - val_precision_1: 0.8622 - val_recall_1: 0.8456 - lr: 1.0000e-04\n",
      "Epoch 12/12\n",
      "205/205 [==============================] - 119s 583ms/step - loss: 14.5464 - accuracy: 0.9355 - precision_1: 0.9442 - recall_1: 0.9241 - val_loss: 14.5977 - val_accuracy: 0.9081 - val_precision_1: 0.9162 - val_recall_1: 0.8938 - lr: 1.0000e-04\n",
      "68/68 [==============================] - 28s 420ms/step - loss: 14.6023 - accuracy: 0.9040 - precision_1: 0.9167 - recall_1: 0.8906\n",
      "Test accuracy with augmentation and regularization: 90.40%\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-06-19 02:56:46.673114: W tensorflow/python/util/util.cc:368] Sets are not currently considered sequences, but this may change in the future, so consider avoiding using them.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: final_model/assets\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/apps/tensorflow/2.7.0/lib/python3.9/site-packages/keras/engine/functional.py:1410: CustomMaskWarning: Custom mask layers require a config and must override get_config. When loading, the custom mask layer must be passed to the custom_objects argument.\n",
      "  layer_config = serialize_layer_fn(layer)\n",
      "/apps/tensorflow/2.7.0/lib/python3.9/site-packages/keras/saving/saved_model/layer_serialization.py:112: CustomMaskWarning: Custom mask layers require a config and must override get_config. When loading, the custom mask layer must be passed to the custom_objects argument.\n",
      "  return generic_utils.serialize_keras_object(obj)\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import cv2\n",
    "import tensorflow as tf\n",
    "from tensorflow.keras.layers import Input, Flatten, Dense, Dropout\n",
    "from tensorflow.keras.models import Model\n",
    "from tensorflow.keras.applications import ResNet50\n",
    "from tensorflow.keras.optimizers import Adam\n",
    "from tensorflow.keras.preprocessing.image import ImageDataGenerator\n",
    "from tensorflow.keras.callbacks import EarlyStopping, ReduceLROnPlateau, ModelCheckpoint\n",
    "from tensorflow.keras.metrics import Precision, Recall\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "# TensorFlow GPU configuration\n",
    "physical_devices = tf.config.list_physical_devices('GPU')\n",
    "if len(physical_devices) > 0:\n",
    "    tf.config.experimental.set_memory_growth(physical_devices[0], True)\n",
    "    print(\"Using GPU:\", physical_devices[0])\n",
    "else:\n",
    "    print(\"No GPU found, using CPU\")\n",
    "\n",
    "# Set up paths and categories\n",
    "base_data_dir = '/blue/srampazzi/vi.gade/cov/covid'\n",
    "categories = ['COVID', 'Lung_Opacity', 'Normal', 'Viral_Pneumonia']\n",
    "\n",
    "# Load metadata and preprocess\n",
    "all_metadata = pd.DataFrame()\n",
    "for category in categories:\n",
    "    path = f'{base_data_dir}/{category}.metadata.xlsx'\n",
    "    df = pd.read_excel(path, usecols=['FILE NAME', 'FORMAT', 'SIZE'])\n",
    "    df['label'] = category\n",
    "    df['image_path'] = df['FILE NAME'].apply(lambda x: f'{base_data_dir}/{category}/images/{x}.png')\n",
    "    df['mask_path'] = df['FILE NAME'].apply(lambda x: f'{base_data_dir}/{category}/masks/{x}.png')\n",
    "    df = df[df['image_path'].apply(os.path.exists)]  # Ensure file exists\n",
    "    all_metadata = pd.concat([all_metadata, df], ignore_index=True)\n",
    "\n",
    "# Data splitting\n",
    "train_df, temp_df = train_test_split(all_metadata, test_size=0.4, random_state=42)\n",
    "val_df, test_df = train_test_split(temp_df, test_size=0.5, random_state=42)\n",
    "\n",
    "# Data augmentation\n",
    "datagen = ImageDataGenerator(\n",
    "    rotation_range=20,\n",
    "    width_shift_range=0.2,\n",
    "    height_shift_range=0.2,\n",
    "    shear_range=0.2,\n",
    "    zoom_range=0.2,\n",
    "    horizontal_flip=True,\n",
    "    fill_mode='nearest'\n",
    ")\n",
    "\n",
    "# Function to apply mask\n",
    "def apply_mask(image, mask):\n",
    "    mask = cv2.resize(mask, (image.shape[1], image.shape[0]))  # Resize mask to match image size\n",
    "    return cv2.bitwise_and(image, image, mask=mask)\n",
    "\n",
    "# Data generator function with data augmentation and masks\n",
    "def data_generator_augmented_with_masks(df, batch_size=32):\n",
    "    while True:\n",
    "        batch_paths = df.sample(n=batch_size)\n",
    "        batch_input = []\n",
    "        batch_output = []\n",
    "        for _, row in batch_paths.iterrows():\n",
    "            image = cv2.imread(row['image_path'], cv2.IMREAD_COLOR)\n",
    "            mask = cv2.imread(row['mask_path'], cv2.IMREAD_GRAYSCALE)  # Load the mask\n",
    "            if mask is not None:  # Ensure mask is loaded correctly\n",
    "                masked_image = apply_mask(image, mask)  # Apply the mask to the image\n",
    "            else:\n",
    "                masked_image = image\n",
    "            image = cv2.resize(masked_image, (256, 256))\n",
    "            image = image / 255.0\n",
    "            image = datagen.random_transform(image)\n",
    "            batch_input.append(image)\n",
    "            batch_output.append(tf.keras.utils.to_categorical(categories.index(row['label']), num_classes=len(categories)))\n",
    "        batch_x = np.array(batch_input)\n",
    "        batch_y = np.array(batch_output)\n",
    "        yield batch_x, batch_y\n",
    "\n",
    "# Setup data generators with data augmentation and masks\n",
    "train_gen_augmented = data_generator_augmented_with_masks(train_df, batch_size=32)\n",
    "val_gen_augmented = data_generator_augmented_with_masks(val_df, batch_size=32)\n",
    "test_gen_augmented = data_generator_augmented_with_masks(test_df, batch_size=32)\n",
    "\n",
    "# Model building with increased regularization\n",
    "base_model = ResNet50(weights='imagenet', include_top=False, input_tensor=Input(shape=(256, 256, 3)))\n",
    "for layer in base_model.layers[-10:]:\n",
    "    layer.trainable = True  # Fine-tune the last 10 layers\n",
    "\n",
    "# Add custom layers with L1/L2 regularization\n",
    "regularizer = tf.keras.regularizers.l1_l2(l2=0.5)\n",
    "x = Flatten()(base_model.output)\n",
    "x = Dense(1024, activation='relu', kernel_regularizer=regularizer)(x)\n",
    "x = Dropout(0.5)(x)\n",
    "predictions = Dense(len(categories), activation='softmax', kernel_regularizer=regularizer)(x)\n",
    "model = Model(inputs=base_model.input, outputs=predictions)\n",
    "\n",
    "# Compile the model with custom metrics\n",
    "model.compile(optimizer=Adam(learning_rate=0.0001),\n",
    "              loss='categorical_crossentropy',\n",
    "              metrics=['accuracy', Precision(), Recall()])\n",
    "\n",
    "# Callbacks for early stopping, model checkpoint, and learning rate reduction\n",
    "early_stopping = EarlyStopping(monitor='val_loss', patience=5, restore_best_weights=True)\n",
    "reduce_lr = ReduceLROnPlateau(monitor='val_loss', factor=0.2, patience=3, min_lr=0.00001)\n",
    "model_checkpoint = ModelCheckpoint('best_model.h5', save_best_only=True, monitor='val_loss')\n",
    "\n",
    "# Model training with data augmentation and regularization\n",
    "history_augmented = model.fit(\n",
    "    train_gen_augmented,\n",
    "    steps_per_epoch=len(train_df) // 32,\n",
    "    validation_data=val_gen_augmented,\n",
    "    validation_steps=len(val_df) // 32,\n",
    "    epochs=12,\n",
    "    callbacks=[early_stopping, reduce_lr, model_checkpoint]\n",
    ")\n",
    "\n",
    "# Evaluate the model on the test set with augmentation\n",
    "test_results_augmented = model.evaluate(test_gen_augmented, steps=len(test_df) // 32)\n",
    "print(f\"Test accuracy with augmentation and regularization: {test_results_augmented[1]*100:.2f}%\")\n",
    "\n",
    "# Save the model in TensorFlow SavedModel format\n",
    "model.save('final_model')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Tensorflow-2.7.0",
   "language": "python",
   "name": "tensorflow-2.7.0"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
